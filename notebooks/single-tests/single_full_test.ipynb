{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from etnn.nn.baseline import create_baseline_model, calc_params\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "from etnn.tools.training import train_epoch, eval_epoch\n",
    "from etnn import TreeNode\n",
    "from etnn.nn.layer_framework import LayerManagementFramework\n",
    "from etnn.routines.run_config import choice_trainloader, choice_loss, choice_optim\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from etnn.data.ferris_wheel import load_pure_ferris_wheel_dataset_single_node\n",
    "from etnn.tools.training_tools import ConfigStore, seeding_all\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-10T19:04:11.351051Z",
     "end_time": "2023-12-10T19:04:13.206216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset_path = \"../../datasets/\"\n",
    "test_perc = 0.3\n",
    "stability_count = 5\n",
    "label = \"tree-advanced\" # although irrelevant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-10T19:04:13.210215Z",
     "end_time": "2023-12-10T19:04:13.218582Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_plot(\n",
    "        df,\n",
    "        what: str = \"r2\"\n",
    ") -> None:\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the initial data\n",
    "    for config_id in df.config_id.unique():\n",
    "        # make subdataset for config id\n",
    "        sub_df = df[df.config_id == config_id]\n",
    "        # plot train test and val\n",
    "        for mode in ['train', 'test', 'val']:\n",
    "            # plot training\n",
    "            if f\"{mode}_{what}\" in sub_df.columns:\n",
    "                plt.plot(sub_df.epoch, sub_df[f\"{mode}_{what}\"], label=f\"{config_id}_{mode}-{what}\")\n",
    "\n",
    "    plt.title(f\"{what} plot\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"score\")\n",
    "    if what == \"r2\":\n",
    "        plt.ylim(-1, +1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-10T19:04:13.818555Z",
     "end_time": "2023-12-10T19:04:13.836553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-12-10T19:04:14.907114Z",
     "end_time": "2023-12-10T19:04:14.927112Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(i, entry, size_elem, normalized, node_type):\n",
    "    # init default config\n",
    "    config = ConfigStore(\n",
    "        in_dim=15,\n",
    "        hidden_dim=int(entry.params_hidden_dim),\n",
    "        out_dim=1,\n",
    "        k=int(entry.params_k),\n",
    "        dataset=-1 if normalized else 0,\n",
    "        ds_size=10_000,\n",
    "        num_gondolas=-1,\n",
    "        num_part_pg=-1,\n",
    "        loss_name='mse',\n",
    "        optimizer_name='adam',\n",
    "        num_max_epochs=300, # real: 100\n",
    "        learning_rate=float(entry.params_learning_rate),\n",
    "        batch_size=1024,\n",
    "        early_stop_tol=5,\n",
    "        use_equal_batcher=bool(entry.params_batcher),\n",
    "        seed=420,\n",
    "        label_type=label,\n",
    "        final_label_factor=5/1000\n",
    "    )\n",
    "\n",
    "    # loading dataset\n",
    "    dataset, df_index = load_pure_ferris_wheel_dataset_single_node(\n",
    "        node_type=node_type,\n",
    "        num_elem=size_elem,\n",
    "        num_to_generate=config.ds_size,\n",
    "        dataset_path=dataset_path,\n",
    "        final_label_factor=config.final_label_factor,\n",
    "        normalize=True if config.dataset == -1 else 0\n",
    "    )\n",
    "    # splitting off test dataset\n",
    "    generator = torch.Generator().manual_seed(config.seed)\n",
    "    train_ds, test_ds= random_split(\n",
    "        dataset,\n",
    "        [1 - test_perc, test_perc],\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    # loaders\n",
    "    train_loader = choice_trainloader(config, df_index, train_ds)\n",
    "    test_loader = DataLoader(test_ds, batch_size=4 * config.batch_size, shuffle=False)\n",
    "\n",
    "    # define device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # set seed for reproducability\n",
    "    seeding_all(config.seed)\n",
    "\n",
    "    # define model\n",
    "    model = LayerManagementFramework(\n",
    "        in_dim=config.in_dim,\n",
    "        tree=TreeNode(node_type, [TreeNode(\"E\", size_elem)]),\n",
    "        hidden_dim=config.hidden_dim,\n",
    "        out_dim=config.out_dim,\n",
    "        k=config.k\n",
    "    ).to(device)\n",
    "\n",
    "    # learning tools\n",
    "    criterion = choice_loss(config)\n",
    "    optimizer = choice_optim(config, model)\n",
    "\n",
    "    # init score list\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    file_name = f\"single-node_node-type-{node_type}_rank-{i}_normalized-{normalized}_n-{size_elem}.csv\"\n",
    "    if os.path.isfile(file_name):\n",
    "        df = pd.read_csv(file_name)\n",
    "    else:\n",
    "        # train for specified number of epochs\n",
    "        for epoch in tqdm(range(config.num_max_epochs)):\n",
    "            train_loss, train_true_y, train_pred_y = train_epoch(\n",
    "                model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                device,\n",
    "                criterion\n",
    "            )\n",
    "\n",
    "            test_loss, test_true_y, test_pred_y = eval_epoch(\n",
    "                model,\n",
    "                test_loader,\n",
    "                device,\n",
    "                criterion\n",
    "            )\n",
    "\n",
    "            # calc r2 score and append\n",
    "            train_r2_list += [r2_score(y_true=train_true_y, y_pred=train_pred_y)]\n",
    "            test_r2_list += [r2_score(y_true=test_true_y, y_pred=test_pred_y)]\n",
    "            train_loss_list += [train_loss.item()]\n",
    "            test_loss_list += [test_loss.item()]\n",
    "\n",
    "        # REPEAT FOR BASELINE MODEL\n",
    "        seeding_all(config.seed)\n",
    "        # %%\n",
    "        model, _ = create_baseline_model(\n",
    "            n_params=calc_params(model),\n",
    "            input_dim=config.in_dim * size_elem,\n",
    "            n_layer=3,\n",
    "            output_dim=1\n",
    "        )\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = choice_optim(config, model)\n",
    "\n",
    "        # train for N epochs\n",
    "        for epoch in tqdm(range(config.num_max_epochs)):\n",
    "            train_loss, train_true_y, train_pred_y = train_epoch(\n",
    "                model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                device,\n",
    "                criterion\n",
    "            )\n",
    "\n",
    "            test_loss, test_true_y, test_pred_y = eval_epoch(\n",
    "                model,\n",
    "                test_loader,\n",
    "                device,\n",
    "                criterion\n",
    "            )\n",
    "\n",
    "            # calc r2 score and append\n",
    "            train_r2_list += [r2_score(y_true=train_true_y, y_pred=train_pred_y)]\n",
    "            test_r2_list += [r2_score(y_true=test_true_y, y_pred=test_pred_y)]\n",
    "            train_loss_list += [train_loss.item()]\n",
    "            test_loss_list += [test_loss.item()]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"config_id\": [\"etnn\"]*config.num_max_epochs + [\"baseline\"]*config.num_max_epochs,\n",
    "            \"epoch\": list(range(1, config.num_max_epochs + 1))*2,\n",
    "            \"train_loss\": train_loss_list,\n",
    "            \"test_loss\": test_loss_list,\n",
    "            \"train_r2\": train_r2_list,\n",
    "            \"test_r2\": test_r2_list\n",
    "        })\n",
    "        df.to_csv(file_name)\n",
    "\n",
    "    # plotting\n",
    "    create_plot(df, \"r2\")\n",
    "    create_plot(df, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# S"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 parameter configuration: Unnamed: 0                                      19\n",
      "number                                          19\n",
      "value                                      0.88093\n",
      "datetime_start          2023-12-10 17:17:40.490020\n",
      "datetime_complete       2023-12-10 17:19:24.879322\n",
      "duration                    0 days 00:01:44.389302\n",
      "params_batcher                               False\n",
      "params_hidden_dim                              368\n",
      "params_k                                         1\n",
      "params_learning_rate                      0.000036\n",
      "state                                     COMPLETE\n",
      "Name: 19, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 63/300 [03:50<14:43,  3.73s/it]"
     ]
    }
   ],
   "source": [
    "normalized = False\n",
    "size_elem = 10\n",
    "node_type = \"S\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-10T17:05:23.684770Z",
     "end_time": "2023-12-10T17:05:23.684770Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = True\n",
    "size_elem = 10\n",
    "node_type = \"S\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = False\n",
    "size_elem = 10\n",
    "node_type = \"Q\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = True\n",
    "size_elem = 10\n",
    "node_type = \"Q\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = False\n",
    "size_elem = 10\n",
    "node_type = \"C\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = True\n",
    "size_elem = 10\n",
    "node_type = \"C\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# P"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = False\n",
    "size_elem = 10\n",
    "node_type = \"P\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized = True\n",
    "size_elem = 10\n",
    "node_type = \"S\"\n",
    "\n",
    "config_table = pd.read_csv(f\"single-node_t-{node_type}_n-{size_elem}_normalized-{normalized}.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    run(i, entry, size_elem, normalized, node_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
