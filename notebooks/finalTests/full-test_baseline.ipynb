{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Full test ETNN configs determined by optuna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing section"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from etnn.nn.baseline import create_baseline_model, calc_params\n",
    "from etnn.tools.training import train_epoch, eval_epoch\n",
    "\n",
    "sys.path.insert(0, os.path.pardir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-08T16:09:19.035567Z",
     "end_time": "2023-12-08T16:09:19.048568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from etnn.routines.run_config import run_config, choice_optim, choice_loss, choice_trainloader, acquire_config_idx, \\\n",
    "    choice_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from etnn.tools.training_tools import ConfigStore, seeding_all, EpochControl, AccuracyManager"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-08T16:24:41.315827Z",
     "end_time": "2023-12-08T16:24:43.280251Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definitions section"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_baseline_custom(\n",
    "        model,\n",
    "        config,\n",
    "        device: str = \"cuda\" if torch.cuda.is_available() else 'cpu',\n",
    "        dataset_path: str = \"../../datasets\"\n",
    "):\n",
    "    # definition of constants\n",
    "    test_perc = 0.3\n",
    "\n",
    "    # CHOICES FOR DATASET\n",
    "    dataset, df_index = choice_dataset(config, dataset_path)\n",
    "\n",
    "    # SPLITTING DATASET IN TRAIN AND VAL\n",
    "    generator = torch.Generator().manual_seed(config.seed)\n",
    "    train_ds, test_ds = random_split(\n",
    "        dataset,\n",
    "        [1 - test_perc, test_perc],\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    # ESTABLISHMENT OF LOADERS\n",
    "    train_loader = choice_trainloader(config, df_index, train_ds)\n",
    "\n",
    "    test_loader = DataLoader(test_ds, batch_size=4 * config.batch_size, shuffle=False)\n",
    "\n",
    "    # DEFINE LOSS AND OPTIMIZER\n",
    "    criterion = choice_loss(config)\n",
    "\n",
    "    # set seeds\n",
    "    seeding_all(config.seed)\n",
    "\n",
    "    # move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = choice_optim(config, model)\n",
    "\n",
    "    # init storage containers\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_r2 = []\n",
    "    test_r2 = []\n",
    "\n",
    "    # train for N epochs\n",
    "    for _ in tqdm(range(config.num_max_epochs)):\n",
    "        train_mean_loss, train_true_y, train_pred_y = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            device,\n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        test_mean_loss, test_true_y, test_pred_y = eval_epoch(\n",
    "            model,\n",
    "            test_loader,\n",
    "            device,\n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        train_loss += [train_mean_loss]\n",
    "        test_loss += [test_mean_loss]\n",
    "        train_r2 += [r2_score(y_true=train_true_y, y_pred=train_pred_y)]\n",
    "        test_r2 += [r2_score(y_true=test_true_y, y_pred=test_pred_y)]\n",
    "\n",
    "    # fuze dataset and save\n",
    "    df = pd.DataFrame({\n",
    "        \"epoch\": list(range(1, config.num_max_epochs + 1)),\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2\n",
    "    })\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_plot(\n",
    "        df,\n",
    "        what: str = \"r2\"\n",
    ") -> None:\n",
    "    plt.figure()\n",
    "    # load data\n",
    "    df_measures = df\n",
    "\n",
    "    # Plot the initial data\n",
    "    for config_id in df_measures.config_id.unique():\n",
    "        # make subdataset for config id\n",
    "        sub_df = df_measures[df_measures.config_id == config_id]\n",
    "\n",
    "        # plot train test and val\n",
    "        for mode in ['train', 'test', 'val']:\n",
    "            # plot training\n",
    "            plt.plot(sub_df.epoch, sub_df[f\"{mode}_{what}\"], label=f\"{config_id}_{mode}-{what}\")\n",
    "\n",
    "    plt.title(f\"{what} plot\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"score\")\n",
    "    if what == \"r2\":\n",
    "        plt.ylim(-1, +1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-08T16:09:21.340264Z",
     "end_time": "2023-12-08T16:09:21.353797Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tree advanced label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define label to show\n",
    "label = \"tree_advanced\"\n",
    "\n",
    "# load config storage\n",
    "config_table = pd.read_csv(\"study_label-tree-advanced_baseline.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    # setup config\n",
    "    config = ConfigStore(\n",
    "        in_dim=15,\n",
    "        hidden_dim=int(entry.params_hidden_dim),\n",
    "        out_dim=1,\n",
    "        k=int(entry.params_k),\n",
    "        dataset=0,\n",
    "        ds_size=10_000,\n",
    "        num_gondolas=10,\n",
    "        num_part_pg=5,\n",
    "        loss_name='mse',\n",
    "        optimizer_name='adam',\n",
    "        num_max_epochs=300,\n",
    "        learning_rate=float(entry.params_learning_rate),\n",
    "        batch_size=1024,\n",
    "        early_stop_tol=5,\n",
    "        use_equal_batcher=bool(entry.params_batcher),\n",
    "        seed=420,\n",
    "        label_type=label,\n",
    "        final_label_factor=1/1000\n",
    "    )\n",
    "\n",
    "    # build model\n",
    "    # define model\n",
    "    layer_list = [torch.nn.Flatten()]\n",
    "    features = config.in_dim * config.num_gondolas * config.num_part_pg\n",
    "\n",
    "    # for each layer create a linear layer and relu (except last one)\n",
    "    for i in range(int(entry.params_n_layers)-1):\n",
    "        # determine new feature dimension\n",
    "        new_features = int(entry[f\"params_n_dim_{i}\"])\n",
    "\n",
    "        # add layer and relu to list\n",
    "        layer_list += [torch.nn.Linear(features, new_features), torch.nn.ReLU()]\n",
    "\n",
    "        # set the new feature to be the current feature\n",
    "        features = new_features\n",
    "\n",
    "    # set the last layer - this one must map to the out dimension\n",
    "    layer_list += [torch.nn.Linear(features, config.out_dim)]\n",
    "    model = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "    # run config and retrieve measurements\n",
    "    df = run_baseline_custom(\n",
    "        model=model,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # save measurements\n",
    "    df.to_csv(f\"baseline_label-{label}_rank-{i}.csv\")\n",
    "\n",
    "    # plot results\n",
    "    create_plot(df, what=\"r2\")\n",
    "    create_plot(df, what=\"loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tree label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define label to show\n",
    "label = \"tree\"\n",
    "\n",
    "# load config storage\n",
    "config_table = pd.read_csv(\"study_label-tree_baseline.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    # setup config\n",
    "    config = ConfigStore(\n",
    "        in_dim=15,\n",
    "        hidden_dim=int(entry.params_hidden_dim),\n",
    "        out_dim=1,\n",
    "        k=int(entry.params_k),\n",
    "        dataset=0,\n",
    "        ds_size=10_000,\n",
    "        num_gondolas=10,\n",
    "        num_part_pg=5,\n",
    "        loss_name='mse',\n",
    "        optimizer_name='adam',\n",
    "        num_max_epochs=300,\n",
    "        learning_rate=float(entry.params_learning_rate),\n",
    "        batch_size=1024,\n",
    "        early_stop_tol=5,\n",
    "        use_equal_batcher=bool(entry.params_batcher),\n",
    "        seed=420,\n",
    "        label_type=label,\n",
    "        final_label_factor=1/1000\n",
    "    )\n",
    "\n",
    "    # build model\n",
    "    # define model\n",
    "    layer_list = [torch.nn.Flatten()]\n",
    "    features = config.in_dim * config.num_gondolas * config.num_part_pg\n",
    "\n",
    "    # for each layer create a linear layer and relu (except last one)\n",
    "    for i in range(int(entry.params_n_layers)-1):\n",
    "        # determine new feature dimension\n",
    "        new_features = int(entry[f\"params_n_dim_{i}\"])\n",
    "\n",
    "        # add layer and relu to list\n",
    "        layer_list += [torch.nn.Linear(features, new_features), torch.nn.ReLU()]\n",
    "\n",
    "        # set the new feature to be the current feature\n",
    "        features = new_features\n",
    "\n",
    "    # set the last layer - this one must map to the out dimension\n",
    "    layer_list += [torch.nn.Linear(features, config.out_dim)]\n",
    "    model = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "    # run config and retrieve measurements\n",
    "    df = run_baseline_custom(\n",
    "        model=model,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # save measurements\n",
    "    df.to_csv(f\"baseline_label-{label}_rank-{i}.csv\")\n",
    "\n",
    "    # plot results\n",
    "    create_plot(df, what=\"r2\")\n",
    "    create_plot(df, what=\"loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Default label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define label to show\n",
    "label = \"default\"\n",
    "\n",
    "# load config storage\n",
    "config_table = pd.read_csv(\"study_label-default_baseline.csv\")\n",
    "\n",
    "# sort config storage\n",
    "config_table = config_table.sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# iterate over top 3 best configs\n",
    "for i in range(3):\n",
    "    # get entry from dataframe\n",
    "    entry = config_table.iloc[i]\n",
    "\n",
    "    # print information to console\n",
    "    print(f\"Rank {i+1} parameter configuration: {entry}\")\n",
    "\n",
    "    # setup config\n",
    "    config = ConfigStore(\n",
    "        in_dim=15,\n",
    "        hidden_dim=int(entry.params_hidden_dim),\n",
    "        out_dim=1,\n",
    "        k=int(entry.params_k),\n",
    "        dataset=0,\n",
    "        ds_size=10_000,\n",
    "        num_gondolas=10,\n",
    "        num_part_pg=5,\n",
    "        loss_name='mse',\n",
    "        optimizer_name='adam',\n",
    "        num_max_epochs=300,\n",
    "        learning_rate=float(entry.params_learning_rate),\n",
    "        batch_size=1024,\n",
    "        early_stop_tol=5,\n",
    "        use_equal_batcher=bool(entry.params_batcher),\n",
    "        seed=420,\n",
    "        label_type=label,\n",
    "        final_label_factor=1/1000\n",
    "    )\n",
    "\n",
    "    # build model\n",
    "    # define model\n",
    "    layer_list = [torch.nn.Flatten()]\n",
    "    features = config.in_dim * config.num_gondolas * config.num_part_pg\n",
    "\n",
    "    # for each layer create a linear layer and relu (except last one)\n",
    "    for i in range(int(entry.params_n_layers)-1):\n",
    "        # determine new feature dimension\n",
    "        new_features = int(entry[f\"params_n_dim_{i}\"])\n",
    "\n",
    "        # add layer and relu to list\n",
    "        layer_list += [torch.nn.Linear(features, new_features), torch.nn.ReLU()]\n",
    "\n",
    "        # set the new feature to be the current feature\n",
    "        features = new_features\n",
    "\n",
    "    # set the last layer - this one must map to the out dimension\n",
    "    layer_list += [torch.nn.Linear(features, config.out_dim)]\n",
    "    model = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "    # run config and retrieve measurements\n",
    "    df = run_baseline_custom(\n",
    "        model=model,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # save measurements\n",
    "    df.to_csv(f\"baseline_label-{label}_rank-{i}.csv\")\n",
    "\n",
    "    # plot results\n",
    "    create_plot(df, what=\"r2\")\n",
    "    create_plot(df, what=\"loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
