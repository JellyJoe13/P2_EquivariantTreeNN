{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter search with optuna - BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:15:39.499927Z",
     "end_time": "2023-12-08T08:15:45.978689Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from etnn import TreeNode\n",
    "from etnn.nn.layer_framework import LayerManagementFramework\n",
    "from etnn.routines.run_config import choice_dataset, choice_trainloader, choice_loss, choice_optim\n",
    "from etnn.tools.training import train_epoch, eval_epoch\n",
    "from etnn.tools.training_tools import ConfigStore, seeding_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of objective function for ETNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T16:33:45.617750Z",
     "start_time": "2023-12-07T16:33:45.607746Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # init default config\n",
    "    config = ConfigStore(\n",
    "        in_dim=15,\n",
    "        hidden_dim=0, #trial.suggest_int(\"hidden_dim\", 16, 512, step=16),\n",
    "        out_dim=1,\n",
    "        k=0, #trial.suggest_int(\"k\", 1, 5),\n",
    "        dataset=0,\n",
    "        ds_size=10_000,\n",
    "        num_gondolas=10,\n",
    "        num_part_pg=5,\n",
    "        loss_name='mse',\n",
    "        optimizer_name='adam',\n",
    "        num_max_epochs=30, # real: 100\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True),\n",
    "        batch_size=1024,\n",
    "        early_stop_tol=5,\n",
    "        use_equal_batcher=trial.suggest_categorical(\"batcher\", [True, False]),\n",
    "        seed=420,\n",
    "        label_type=label,\n",
    "        final_label_factor=1/1000\n",
    "    )\n",
    "\n",
    "    # loading dataset\n",
    "    dataset, df_index = choice_dataset(config, dataset_path)\n",
    "    # splitting off test dataset\n",
    "    generator = torch.Generator().manual_seed(config.seed)\n",
    "    train_ds, val_ds, _ = random_split(\n",
    "        dataset,\n",
    "        [1 - test_perc - val_perc, val_perc, test_perc],\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    # loaders\n",
    "    train_loader = choice_trainloader(config, df_index, train_ds)\n",
    "    val_loader = DataLoader(val_ds, batch_size=4 * config.batch_size, shuffle=False)\n",
    "\n",
    "    # build tree\n",
    "    tree_structure = TreeNode(\n",
    "        node_type=\"C\",\n",
    "        children=[\n",
    "            TreeNode(\"P\", [TreeNode(\"E\", config.num_part_pg)])\n",
    "            for _ in range(config.num_gondolas)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # define device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # set seed for reproducability\n",
    "    seeding_all(config.seed)\n",
    "\n",
    "    # define model\n",
    "    layer_list = [torch.nn.Flatten()]\n",
    "    features = config.in_dim * config.num_gondolas * config.num_part_pg\n",
    "\n",
    "    # for each layer create a linear layer and relu (except last one)\n",
    "    for i in range(trial.suggest_int(\"n_layers\", 1, 5)-1):\n",
    "        # determine new feature dimension\n",
    "        new_features = trial.suggest_int(f\"n_dim_{i}\", 1, 512)\n",
    "\n",
    "        # add layer and relu to list\n",
    "        layer_list += [torch.nn.Linear(features, new_features), torch.nn.ReLU()]\n",
    "\n",
    "        # set the new feature to be the current feature\n",
    "        features = new_features\n",
    "\n",
    "    # set the last layer - this one must map to the out dimension\n",
    "    layer_list += [torch.nn.Linear(features, config.out_dim)]\n",
    "    model = torch.nn.Sequential(*layer_list).to(device)\n",
    "\n",
    "    # learning tools\n",
    "    criterion = choice_loss(config)\n",
    "    optimizer = choice_optim(config, model)\n",
    "\n",
    "    # init score list\n",
    "    score_list = []\n",
    "\n",
    "    # train for specified number of epochs\n",
    "    for epoch in range(config.num_max_epochs):\n",
    "        _, _, _ = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            device,\n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        _, val_true_y, val_pred_y = eval_epoch(\n",
    "            model,\n",
    "            val_loader,\n",
    "            device,\n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        # calc r2 score and append\n",
    "        score = r2_score(y_true=val_true_y, y_pred=val_pred_y)\n",
    "        score_list += [score]\n",
    "        trial.report(score, epoch)\n",
    "\n",
    "    # calculate objective\n",
    "    # display(score_list)\n",
    "    # idea: last x r2 scores (why not last one? for stability purposes)\n",
    "    obj = np.array(score_list)[-stability_count:]\n",
    "    return np.mean(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree advanced label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T16:33:45.644754Z",
     "start_time": "2023-12-07T16:33:45.618746Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting global parameters\n",
    "dataset_path = \"../../datasets/\"\n",
    "label = \"tree_advanced\" # alt: tree or default\n",
    "test_perc = 0.3\n",
    "val_perc = 0.21\n",
    "stability_count = 5\n",
    "n_trials = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T00:46:10.138020Z",
     "start_time": "2023-12-06T23:22:13.482574Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 19:03:23,890] A new study created in memory with name: Best tree advanced label config\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feed250ffc9f4ba9aa5adb61e268f058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 19:04:38,585] Trial 0 finished with value: -24750.47571961474 and parameters: {'learning_rate': 0.004047065387150369, 'batcher': False, 'n_layers': 1}. Best is trial 0 with value: -24750.47571961474.\n",
      "[I 2023-12-07 19:06:12,288] Trial 1 finished with value: -145200.10870485418 and parameters: {'learning_rate': 0.0002813629489521779, 'batcher': True, 'n_layers': 1}. Best is trial 0 with value: -24750.47571961474.\n",
      "[I 2023-12-07 19:08:03,845] Trial 2 finished with value: -3.5193973016892506 and parameters: {'learning_rate': 0.0009736335534809103, 'batcher': True, 'n_layers': 4, 'n_dim_0': 210, 'n_dim_1': 404, 'n_dim_2': 435}. Best is trial 2 with value: -3.5193973016892506.\n",
      "[I 2023-12-07 19:09:47,026] Trial 3 finished with value: -860.5048661204946 and parameters: {'learning_rate': 1.538543338413527e-05, 'batcher': True, 'n_layers': 3, 'n_dim_0': 38, 'n_dim_1': 473}. Best is trial 2 with value: -3.5193973016892506.\n",
      "[I 2023-12-07 19:11:31,903] Trial 4 finished with value: -53.30276535396663 and parameters: {'learning_rate': 1.710126415201465e-05, 'batcher': False, 'n_layers': 4, 'n_dim_0': 473, 'n_dim_1': 390, 'n_dim_2': 511}. Best is trial 2 with value: -3.5193973016892506.\n",
      "[I 2023-12-07 19:13:22,937] Trial 5 finished with value: -13.182749792392386 and parameters: {'learning_rate': 0.00020323620549328298, 'batcher': False, 'n_layers': 4, 'n_dim_0': 174, 'n_dim_1': 65, 'n_dim_2': 381}. Best is trial 2 with value: -3.5193973016892506.\n",
      "[I 2023-12-07 19:15:05,205] Trial 6 finished with value: -13.962741377166989 and parameters: {'learning_rate': 0.0027358923833014064, 'batcher': False, 'n_layers': 3, 'n_dim_0': 52, 'n_dim_1': 190}. Best is trial 2 with value: -3.5193973016892506.\n",
      "[I 2023-12-07 19:16:45,665] Trial 7 finished with value: -145250.8709209753 and parameters: {'learning_rate': 0.00028056400911395267, 'batcher': True, 'n_layers': 1}. Best is trial 2 with value: -3.5193973016892506.\n",
      "[I 2023-12-07 19:18:33,476] Trial 8 finished with value: -0.9914587876877647 and parameters: {'learning_rate': 0.0003769697597153821, 'batcher': False, 'n_layers': 5, 'n_dim_0': 240, 'n_dim_1': 91, 'n_dim_2': 247, 'n_dim_3': 310}. Best is trial 8 with value: -0.9914587876877647.\n",
      "[I 2023-12-07 19:20:22,328] Trial 9 finished with value: -1653.557766437339 and parameters: {'learning_rate': 8.984824894879796e-05, 'batcher': True, 'n_layers': 2, 'n_dim_0': 243}. Best is trial 8 with value: -0.9914587876877647.\n",
      "[I 2023-12-07 19:22:08,225] Trial 10 finished with value: -0.004747773641957442 and parameters: {'learning_rate': 0.007755689737299679, 'batcher': False, 'n_layers': 5, 'n_dim_0': 404, 'n_dim_1': 20, 'n_dim_2': 89, 'n_dim_3': 298}. Best is trial 10 with value: -0.004747773641957442.\n",
      "[I 2023-12-07 19:23:37,123] Trial 11 finished with value: -0.020483543528925053 and parameters: {'learning_rate': 0.009451908702362963, 'batcher': False, 'n_layers': 5, 'n_dim_0': 419, 'n_dim_1': 36, 'n_dim_2': 63, 'n_dim_3': 307}. Best is trial 10 with value: -0.004747773641957442.\n",
      "[I 2023-12-07 19:25:27,791] Trial 12 finished with value: -0.002459447279529492 and parameters: {'learning_rate': 0.007625155404278354, 'batcher': False, 'n_layers': 5, 'n_dim_0': 441, 'n_dim_1': 12, 'n_dim_2': 34, 'n_dim_3': 284}. Best is trial 12 with value: -0.002459447279529492.\n",
      "[I 2023-12-07 19:27:00,364] Trial 13 finished with value: -0.01562031699577644 and parameters: {'learning_rate': 0.009979630556122073, 'batcher': False, 'n_layers': 5, 'n_dim_0': 373, 'n_dim_1': 193, 'n_dim_2': 1, 'n_dim_3': 114}. Best is trial 12 with value: -0.002459447279529492.\n",
      "[I 2023-12-07 19:28:27,742] Trial 14 finished with value: -0.04455906359883297 and parameters: {'learning_rate': 0.0025567780929880244, 'batcher': False, 'n_layers': 5, 'n_dim_0': 369, 'n_dim_1': 10, 'n_dim_2': 148, 'n_dim_3': 423}. Best is trial 12 with value: -0.002459447279529492.\n",
      "[I 2023-12-07 19:30:14,320] Trial 15 finished with value: -4.3199127515108415 and parameters: {'learning_rate': 0.0011422686729058971, 'batcher': False, 'n_layers': 4, 'n_dim_0': 511, 'n_dim_1': 145, 'n_dim_2': 135}. Best is trial 12 with value: -0.002459447279529492.\n",
      "[I 2023-12-07 19:32:04,896] Trial 16 finished with value: 0.8639173684700732 and parameters: {'learning_rate': 0.006051448676304329, 'batcher': False, 'n_layers': 5, 'n_dim_0': 322, 'n_dim_1': 291, 'n_dim_2': 137, 'n_dim_3': 175}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:33:50,438] Trial 17 finished with value: -238.68901306660715 and parameters: {'learning_rate': 0.005227886445352602, 'batcher': False, 'n_layers': 2, 'n_dim_0': 319}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:35:36,620] Trial 18 finished with value: -85.6509870955836 and parameters: {'learning_rate': 0.00178954526462879, 'batcher': False, 'n_layers': 3, 'n_dim_0': 315, 'n_dim_1': 297}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:37:27,289] Trial 19 finished with value: -1.2105880368297877 and parameters: {'learning_rate': 0.004316497790412285, 'batcher': False, 'n_layers': 4, 'n_dim_0': 147, 'n_dim_1': 279, 'n_dim_2': 213}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:39:14,268] Trial 20 finished with value: -1026.2141960466365 and parameters: {'learning_rate': 0.0011110694204458356, 'batcher': False, 'n_layers': 5, 'n_dim_0': 309, 'n_dim_1': 361, 'n_dim_2': 7, 'n_dim_3': 90}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:40:59,892] Trial 21 finished with value: -1.633750525744211 and parameters: {'learning_rate': 0.009343641421976351, 'batcher': False, 'n_layers': 5, 'n_dim_0': 436, 'n_dim_1': 142, 'n_dim_2': 108, 'n_dim_3': 209}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:42:49,941] Trial 22 finished with value: -0.002670047352888183 and parameters: {'learning_rate': 0.005959598087429135, 'batcher': False, 'n_layers': 5, 'n_dim_0': 375, 'n_dim_1': 4, 'n_dim_2': 72, 'n_dim_3': 228}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:44:42,725] Trial 23 finished with value: -2.8970094275215335 and parameters: {'learning_rate': 0.004200431495792182, 'batcher': False, 'n_layers': 4, 'n_dim_0': 332, 'n_dim_1': 326, 'n_dim_2': 180}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:46:27,216] Trial 24 finished with value: 0.5444207281061844 and parameters: {'learning_rate': 0.002159879278121359, 'batcher': False, 'n_layers': 5, 'n_dim_0': 445, 'n_dim_1': 228, 'n_dim_2': 53, 'n_dim_3': 185}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:48:17,591] Trial 25 finished with value: -1.572547661240662 and parameters: {'learning_rate': 0.0026759569576966648, 'batcher': False, 'n_layers': 4, 'n_dim_0': 469, 'n_dim_1': 233, 'n_dim_2': 321}. Best is trial 16 with value: 0.8639173684700732.\n",
      "[I 2023-12-07 19:50:09,947] Trial 26 finished with value: 0.9355811634135069 and parameters: {'learning_rate': 0.005620447373414403, 'batcher': True, 'n_layers': 5, 'n_dim_0': 497, 'n_dim_1': 510, 'n_dim_2': 47, 'n_dim_3': 159}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 19:51:59,064] Trial 27 finished with value: -65.09523851545723 and parameters: {'learning_rate': 0.0015819578836582292, 'batcher': True, 'n_layers': 3, 'n_dim_0': 504, 'n_dim_1': 499}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 19:53:51,539] Trial 28 finished with value: 0.6371402079100975 and parameters: {'learning_rate': 0.00409334537893301, 'batcher': True, 'n_layers': 5, 'n_dim_0': 471, 'n_dim_1': 439, 'n_dim_2': 172, 'n_dim_3': 157}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 19:55:42,271] Trial 29 finished with value: -0.191253220214521 and parameters: {'learning_rate': 0.003949011995801557, 'batcher': True, 'n_layers': 4, 'n_dim_0': 275, 'n_dim_1': 450, 'n_dim_2': 184}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 19:57:23,838] Trial 30 finished with value: -254.3143393972141 and parameters: {'learning_rate': 0.005034869817851547, 'batcher': True, 'n_layers': 2, 'n_dim_0': 96}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 19:59:11,960] Trial 31 finished with value: 0.4237908241085827 and parameters: {'learning_rate': 0.0033661828112652448, 'batcher': True, 'n_layers': 5, 'n_dim_0': 474, 'n_dim_1': 439, 'n_dim_2': 125, 'n_dim_3': 154}. Best is trial 26 with value: 0.9355811634135069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 20:01:02,787] Trial 32 finished with value: -1.2392169459826756 and parameters: {'learning_rate': 0.0020097283731976, 'batcher': True, 'n_layers': 5, 'n_dim_0': 456, 'n_dim_1': 512, 'n_dim_2': 67, 'n_dim_3': 167}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:02:52,105] Trial 33 finished with value: -1031.2252599716708 and parameters: {'learning_rate': 0.005975091704208469, 'batcher': True, 'n_layers': 5, 'n_dim_0': 508, 'n_dim_1': 343, 'n_dim_2': 173, 'n_dim_3': 63}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:04:32,014] Trial 34 finished with value: -1097.0363806006017 and parameters: {'learning_rate': 0.0031959451616620353, 'batcher': True, 'n_layers': 5, 'n_dim_0': 398, 'n_dim_1': 229, 'n_dim_2': 252, 'n_dim_3': 11}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:06:00,389] Trial 35 finished with value: -1157.7958230462268 and parameters: {'learning_rate': 0.006121679524104839, 'batcher': True, 'n_layers': 4, 'n_dim_0': 355, 'n_dim_1': 409, 'n_dim_2': 39}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:07:47,078] Trial 36 finished with value: -9.789478904308305 and parameters: {'learning_rate': 0.0007284584940952002, 'batcher': True, 'n_layers': 4, 'n_dim_0': 482, 'n_dim_1': 401, 'n_dim_2': 109}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:09:29,466] Trial 37 finished with value: 0.7621145648417307 and parameters: {'learning_rate': 0.001979920671075799, 'batcher': True, 'n_layers': 5, 'n_dim_0': 422, 'n_dim_1': 471, 'n_dim_2': 309, 'n_dim_3': 188}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:11:15,649] Trial 38 finished with value: -2.5738082398955684 and parameters: {'learning_rate': 0.003680421355940991, 'batcher': True, 'n_layers': 4, 'n_dim_0': 410, 'n_dim_1': 471, 'n_dim_2': 304}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:12:53,411] Trial 39 finished with value: -91277.04807770015 and parameters: {'learning_rate': 0.0015105045182159805, 'batcher': True, 'n_layers': 1}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:14:40,931] Trial 40 finished with value: 0.3639529896770681 and parameters: {'learning_rate': 0.00258823852891035, 'batcher': True, 'n_layers': 5, 'n_dim_0': 278, 'n_dim_1': 435, 'n_dim_2': 312, 'n_dim_3': 130}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:16:24,903] Trial 41 finished with value: 0.7416319952868855 and parameters: {'learning_rate': 0.0025514078559477015, 'batcher': True, 'n_layers': 5, 'n_dim_0': 425, 'n_dim_1': 481, 'n_dim_2': 280, 'n_dim_3': 198}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:18:06,101] Trial 42 finished with value: 0.6121969786659585 and parameters: {'learning_rate': 0.006609532983551256, 'batcher': True, 'n_layers': 5, 'n_dim_0': 486, 'n_dim_1': 489, 'n_dim_2': 349, 'n_dim_3': 230}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:19:22,767] Trial 43 finished with value: 0.5827741081643063 and parameters: {'learning_rate': 0.004549876531358425, 'batcher': True, 'n_layers': 5, 'n_dim_0': 421, 'n_dim_1': 466, 'n_dim_2': 279, 'n_dim_3': 175}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:20:36,702] Trial 44 finished with value: 0.7293210386668127 and parameters: {'learning_rate': 0.003443323715797458, 'batcher': True, 'n_layers': 5, 'n_dim_0': 203, 'n_dim_1': 380, 'n_dim_2': 218, 'n_dim_3': 233}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:21:51,713] Trial 45 finished with value: -1.8143138358424262 and parameters: {'learning_rate': 0.0030591931790695127, 'batcher': True, 'n_layers': 4, 'n_dim_0': 197, 'n_dim_1': 380, 'n_dim_2': 413}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:23:06,326] Trial 46 finished with value: 0.6733375801110822 and parameters: {'learning_rate': 0.00748527962059832, 'batcher': True, 'n_layers': 5, 'n_dim_0': 142, 'n_dim_1': 320, 'n_dim_2': 215, 'n_dim_3': 253}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:24:21,902] Trial 47 finished with value: 0.19980002867567165 and parameters: {'learning_rate': 0.0008752540548062473, 'batcher': True, 'n_layers': 5, 'n_dim_0': 218, 'n_dim_1': 411, 'n_dim_2': 223, 'n_dim_3': 203}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:25:39,485] Trial 48 finished with value: -1.4261521420899488 and parameters: {'learning_rate': 0.0022223704635225177, 'batcher': True, 'n_layers': 5, 'n_dim_0': 185, 'n_dim_1': 472, 'n_dim_2': 358, 'n_dim_3': 244}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:26:53,677] Trial 49 finished with value: -1.8537527028433645 and parameters: {'learning_rate': 0.0013742549312069788, 'batcher': True, 'n_layers': 4, 'n_dim_0': 262, 'n_dim_1': 377, 'n_dim_2': 275}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:28:09,282] Trial 50 finished with value: -47.507017196976605 and parameters: {'learning_rate': 0.00987584742450741, 'batcher': True, 'n_layers': 3, 'n_dim_0': 390, 'n_dim_1': 506}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:29:25,437] Trial 51 finished with value: -3.995721289636599 and parameters: {'learning_rate': 0.007480569002012981, 'batcher': True, 'n_layers': 5, 'n_dim_0': 148, 'n_dim_1': 306, 'n_dim_2': 499, 'n_dim_3': 265}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:30:39,642] Trial 52 finished with value: -2.3655296499234297 and parameters: {'learning_rate': 0.007530576808798265, 'batcher': True, 'n_layers': 5, 'n_dim_0': 110, 'n_dim_1': 339, 'n_dim_2': 217, 'n_dim_3': 205}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:31:54,918] Trial 53 finished with value: 0.7461802076555196 and parameters: {'learning_rate': 0.004965073036817335, 'batcher': True, 'n_layers': 5, 'n_dim_0': 216, 'n_dim_1': 265, 'n_dim_2': 270, 'n_dim_3': 264}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:33:11,081] Trial 54 finished with value: 0.7253764892509442 and parameters: {'learning_rate': 0.005438345710012292, 'batcher': True, 'n_layers': 5, 'n_dim_0': 345, 'n_dim_1': 270, 'n_dim_2': 284, 'n_dim_3': 392}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:34:26,363] Trial 55 finished with value: 0.622865288685202 and parameters: {'learning_rate': 0.003218561712577798, 'batcher': True, 'n_layers': 5, 'n_dim_0': 209, 'n_dim_1': 487, 'n_dim_2': 251, 'n_dim_3': 351}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:35:45,398] Trial 56 finished with value: 0.6959703119673674 and parameters: {'learning_rate': 0.0020382997284549816, 'batcher': True, 'n_layers': 5, 'n_dim_0': 237, 'n_dim_1': 164, 'n_dim_2': 338, 'n_dim_3': 480}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:37:45,260] Trial 57 finished with value: -7.605842546834532 and parameters: {'learning_rate': 0.004618323043472762, 'batcher': True, 'n_layers': 4, 'n_dim_0': 431, 'n_dim_1': 250, 'n_dim_2': 384}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:39:35,089] Trial 58 finished with value: 0.8411893032835295 and parameters: {'learning_rate': 0.002894648549822202, 'batcher': True, 'n_layers': 5, 'n_dim_0': 305, 'n_dim_1': 422, 'n_dim_2': 276, 'n_dim_3': 125}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:41:25,457] Trial 59 finished with value: 0.8451604167142855 and parameters: {'learning_rate': 0.0029123424576280527, 'batcher': True, 'n_layers': 5, 'n_dim_0': 297, 'n_dim_1': 98, 'n_dim_2': 296, 'n_dim_3': 123}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:43:19,444] Trial 60 finished with value: -1.965260877252574 and parameters: {'learning_rate': 0.005626823612624122, 'batcher': False, 'n_layers': 4, 'n_dim_0': 297, 'n_dim_1': 93, 'n_dim_2': 241}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:44:39,826] Trial 61 finished with value: 0.4548116197992254 and parameters: {'learning_rate': 0.002434675663641983, 'batcher': True, 'n_layers': 5, 'n_dim_0': 331, 'n_dim_1': 208, 'n_dim_2': 289, 'n_dim_3': 123}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:45:55,649] Trial 62 finished with value: 0.12737349617508353 and parameters: {'learning_rate': 0.0017652066552611941, 'batcher': True, 'n_layers': 5, 'n_dim_0': 286, 'n_dim_1': 453, 'n_dim_2': 334, 'n_dim_3': 85}. Best is trial 26 with value: 0.9355811634135069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 20:47:09,121] Trial 63 finished with value: 0.5931296250009913 and parameters: {'learning_rate': 0.0027394509516266816, 'batcher': True, 'n_layers': 5, 'n_dim_0': 246, 'n_dim_1': 105, 'n_dim_2': 305, 'n_dim_3': 142}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:48:20,856] Trial 64 finished with value: -1169.8736436286435 and parameters: {'learning_rate': 0.004562416715346014, 'batcher': True, 'n_layers': 2, 'n_dim_0': 5}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:49:35,609] Trial 65 finished with value: 0.7496335321717161 and parameters: {'learning_rate': 0.0037634356730918404, 'batcher': True, 'n_layers': 5, 'n_dim_0': 352, 'n_dim_1': 424, 'n_dim_2': 265, 'n_dim_3': 186}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:50:50,234] Trial 66 finished with value: 0.5662733510172068 and parameters: {'learning_rate': 0.004082910174176839, 'batcher': False, 'n_layers': 5, 'n_dim_0': 314, 'n_dim_1': 423, 'n_dim_2': 249, 'n_dim_3': 91}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:52:04,888] Trial 67 finished with value: -0.24574765542405502 and parameters: {'learning_rate': 0.008306667008866203, 'batcher': True, 'n_layers': 5, 'n_dim_0': 372, 'n_dim_1': 49, 'n_dim_2': 268, 'n_dim_3': 286}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:53:18,439] Trial 68 finished with value: -0.6721743191970696 and parameters: {'learning_rate': 0.006775425241168345, 'batcher': False, 'n_layers': 5, 'n_dim_0': 352, 'n_dim_1': 274, 'n_dim_2': 195, 'n_dim_3': 116}. Best is trial 26 with value: 0.9355811634135069.\n",
      "[I 2023-12-07 20:54:30,704] Trial 69 finished with value: -4.1430270069428925 and parameters: {'learning_rate': 0.004990750095231469, 'batcher': True, 'n_layers': 5, 'n_dim_0': 297, 'n_dim_1': 302, 'n_dim_2': 153, 'n_dim_3': 52}. Best is trial 26 with value: 0.9355811634135069.\n"
     ]
    }
   ],
   "source": [
    "study_tree_advanced = optuna.create_study(study_name=\"Best tree advanced label config\", directions=['maximize'])\n",
    "study_tree_advanced.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T00:46:10.185059Z",
     "start_time": "2023-12-07T00:46:10.140018Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.005620447373414403, 'batcher': True, 'n_layers': 5, 'n_dim_0': 497, 'n_dim_1': 510, 'n_dim_2': 47, 'n_dim_3': 159}\n"
     ]
    }
   ],
   "source": [
    "best_par_tree_advanced = study_tree_advanced.best_params\n",
    "print(best_par_tree_advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T00:46:10.186061Z",
     "start_time": "2023-12-07T00:46:10.154061Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPESampler'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_tree_advanced.sampler.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T00:46:10.219060Z",
     "start_time": "2023-12-07T00:46:10.172061Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batcher</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_dim_0</th>\n",
       "      <th>params_n_dim_1</th>\n",
       "      <th>params_n_dim_2</th>\n",
       "      <th>params_n_dim_3</th>\n",
       "      <th>params_n_layers</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-24750.475720</td>\n",
       "      <td>2023-12-07 19:03:23.898191</td>\n",
       "      <td>2023-12-07 19:04:38.585621</td>\n",
       "      <td>0 days 00:01:14.687430</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-145200.108705</td>\n",
       "      <td>2023-12-07 19:04:38.586621</td>\n",
       "      <td>2023-12-07 19:06:12.288189</td>\n",
       "      <td>0 days 00:01:33.701568</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.519397</td>\n",
       "      <td>2023-12-07 19:06:12.290324</td>\n",
       "      <td>2023-12-07 19:08:03.844086</td>\n",
       "      <td>0 days 00:01:51.553762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>210.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-860.504866</td>\n",
       "      <td>2023-12-07 19:08:03.845907</td>\n",
       "      <td>2023-12-07 19:09:47.025777</td>\n",
       "      <td>0 days 00:01:43.179870</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>38.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-53.302765</td>\n",
       "      <td>2023-12-07 19:09:47.028782</td>\n",
       "      <td>2023-12-07 19:11:31.903042</td>\n",
       "      <td>0 days 00:01:44.874260</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>473.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0.749634</td>\n",
       "      <td>2023-12-07 20:48:20.858305</td>\n",
       "      <td>2023-12-07 20:49:35.609636</td>\n",
       "      <td>0 days 00:01:14.751331</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>352.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.566273</td>\n",
       "      <td>2023-12-07 20:49:35.610635</td>\n",
       "      <td>2023-12-07 20:50:50.234949</td>\n",
       "      <td>0 days 00:01:14.624314</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>314.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>-0.245748</td>\n",
       "      <td>2023-12-07 20:50:50.235946</td>\n",
       "      <td>2023-12-07 20:52:04.888581</td>\n",
       "      <td>0 days 00:01:14.652635</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>372.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>-0.672174</td>\n",
       "      <td>2023-12-07 20:52:04.890580</td>\n",
       "      <td>2023-12-07 20:53:18.439272</td>\n",
       "      <td>0 days 00:01:13.548692</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>352.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>-4.143027</td>\n",
       "      <td>2023-12-07 20:53:18.440272</td>\n",
       "      <td>2023-12-07 20:54:30.704920</td>\n",
       "      <td>0 days 00:01:12.264648</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>297.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number          value             datetime_start  \\\n",
       "0        0  -24750.475720 2023-12-07 19:03:23.898191   \n",
       "1        1 -145200.108705 2023-12-07 19:04:38.586621   \n",
       "2        2      -3.519397 2023-12-07 19:06:12.290324   \n",
       "3        3    -860.504866 2023-12-07 19:08:03.845907   \n",
       "4        4     -53.302765 2023-12-07 19:09:47.028782   \n",
       "..     ...            ...                        ...   \n",
       "65      65       0.749634 2023-12-07 20:48:20.858305   \n",
       "66      66       0.566273 2023-12-07 20:49:35.610635   \n",
       "67      67      -0.245748 2023-12-07 20:50:50.235946   \n",
       "68      68      -0.672174 2023-12-07 20:52:04.890580   \n",
       "69      69      -4.143027 2023-12-07 20:53:18.440272   \n",
       "\n",
       "            datetime_complete               duration  params_batcher  \\\n",
       "0  2023-12-07 19:04:38.585621 0 days 00:01:14.687430           False   \n",
       "1  2023-12-07 19:06:12.288189 0 days 00:01:33.701568            True   \n",
       "2  2023-12-07 19:08:03.844086 0 days 00:01:51.553762            True   \n",
       "3  2023-12-07 19:09:47.025777 0 days 00:01:43.179870            True   \n",
       "4  2023-12-07 19:11:31.903042 0 days 00:01:44.874260           False   \n",
       "..                        ...                    ...             ...   \n",
       "65 2023-12-07 20:49:35.609636 0 days 00:01:14.751331            True   \n",
       "66 2023-12-07 20:50:50.234949 0 days 00:01:14.624314           False   \n",
       "67 2023-12-07 20:52:04.888581 0 days 00:01:14.652635            True   \n",
       "68 2023-12-07 20:53:18.439272 0 days 00:01:13.548692           False   \n",
       "69 2023-12-07 20:54:30.704920 0 days 00:01:12.264648            True   \n",
       "\n",
       "    params_learning_rate  params_n_dim_0  params_n_dim_1  params_n_dim_2  \\\n",
       "0               0.004047             NaN             NaN             NaN   \n",
       "1               0.000281             NaN             NaN             NaN   \n",
       "2               0.000974           210.0           404.0           435.0   \n",
       "3               0.000015            38.0           473.0             NaN   \n",
       "4               0.000017           473.0           390.0           511.0   \n",
       "..                   ...             ...             ...             ...   \n",
       "65              0.003763           352.0           424.0           265.0   \n",
       "66              0.004083           314.0           423.0           249.0   \n",
       "67              0.008307           372.0            49.0           268.0   \n",
       "68              0.006775           352.0           274.0           195.0   \n",
       "69              0.004991           297.0           302.0           153.0   \n",
       "\n",
       "    params_n_dim_3  params_n_layers     state  \n",
       "0              NaN                1  COMPLETE  \n",
       "1              NaN                1  COMPLETE  \n",
       "2              NaN                4  COMPLETE  \n",
       "3              NaN                3  COMPLETE  \n",
       "4              NaN                4  COMPLETE  \n",
       "..             ...              ...       ...  \n",
       "65           186.0                5  COMPLETE  \n",
       "66            91.0                5  COMPLETE  \n",
       "67           286.0                5  COMPLETE  \n",
       "68           116.0                5  COMPLETE  \n",
       "69            52.0                5  COMPLETE  \n",
       "\n",
       "[70 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tree_advanced = study_tree_advanced.trials_dataframe()\n",
    "df_tree_advanced.to_csv(\"study_label-tree-advanced_baseline.csv\")\n",
    "display(df_tree_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T00:46:12.364699Z",
     "start_time": "2023-12-07T00:46:12.321807Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# setting global parameters\n",
    "dataset_path = \"../../datasets/\"\n",
    "label = \"tree\" # alt: tree or default\n",
    "test_perc = 0.3\n",
    "val_perc = 0.21\n",
    "stability_count = 5\n",
    "n_trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T02:11:23.297287Z",
     "start_time": "2023-12-07T00:46:12.337700Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 20:55:06,191] A new study created in memory with name: Best tree label config\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c6793430254abfa6912a682b9e1aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 20:56:21,472] Trial 0 finished with value: -210601.94645228545 and parameters: {'learning_rate': 3.5762164835316424e-05, 'batcher': False, 'n_layers': 1}. Best is trial 0 with value: -210601.94645228545.\n",
      "[I 2023-12-07 20:57:36,740] Trial 1 finished with value: -3.337819704364103 and parameters: {'learning_rate': 0.0009340234771113171, 'batcher': True, 'n_layers': 4, 'n_dim_0': 31, 'n_dim_1': 144, 'n_dim_2': 116}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 20:58:50,586] Trial 2 finished with value: -14.395422711268527 and parameters: {'learning_rate': 4.4402445245951924e-05, 'batcher': True, 'n_layers': 4, 'n_dim_0': 25, 'n_dim_1': 50, 'n_dim_2': 453}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:00:03,806] Trial 3 finished with value: -25.24174673544831 and parameters: {'learning_rate': 0.0007706758420370273, 'batcher': True, 'n_layers': 4, 'n_dim_0': 42, 'n_dim_1': 332, 'n_dim_2': 405}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:01:17,092] Trial 4 finished with value: -338.02140201821857 and parameters: {'learning_rate': 9.44549991268405e-05, 'batcher': True, 'n_layers': 3, 'n_dim_0': 66, 'n_dim_1': 437}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:02:31,167] Trial 5 finished with value: -59.435372559425915 and parameters: {'learning_rate': 0.0034598132051023543, 'batcher': True, 'n_layers': 3, 'n_dim_0': 368, 'n_dim_1': 105}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:03:44,919] Trial 6 finished with value: -1101.830884188464 and parameters: {'learning_rate': 0.0043958174860396155, 'batcher': True, 'n_layers': 2, 'n_dim_0': 112}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:05:00,622] Trial 7 finished with value: -809.4910654699524 and parameters: {'learning_rate': 0.0031091570829911183, 'batcher': False, 'n_layers': 2, 'n_dim_0': 465}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:06:15,396] Trial 8 finished with value: -421.87786611240654 and parameters: {'learning_rate': 1.5261914017176167e-05, 'batcher': True, 'n_layers': 4, 'n_dim_0': 102, 'n_dim_1': 491, 'n_dim_2': 118}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:07:32,362] Trial 9 finished with value: -381.9734804348124 and parameters: {'learning_rate': 0.0016540338530523365, 'batcher': True, 'n_layers': 4, 'n_dim_0': 274, 'n_dim_1': 2, 'n_dim_2': 241}. Best is trial 1 with value: -3.337819704364103.\n",
      "[I 2023-12-07 21:08:49,038] Trial 10 finished with value: 0.5417538783454021 and parameters: {'learning_rate': 0.0003044386432340112, 'batcher': False, 'n_layers': 5, 'n_dim_0': 225, 'n_dim_1': 200, 'n_dim_2': 12, 'n_dim_3': 272}. Best is trial 10 with value: 0.5417538783454021.\n",
      "[I 2023-12-07 21:10:04,714] Trial 11 finished with value: -0.3528767867152311 and parameters: {'learning_rate': 0.00031996583063312106, 'batcher': False, 'n_layers': 5, 'n_dim_0': 212, 'n_dim_1': 200, 'n_dim_2': 22, 'n_dim_3': 238}. Best is trial 10 with value: 0.5417538783454021.\n",
      "[I 2023-12-07 21:11:18,596] Trial 12 finished with value: 0.05969129784816871 and parameters: {'learning_rate': 0.00024529841890356057, 'batcher': False, 'n_layers': 5, 'n_dim_0': 213, 'n_dim_1': 229, 'n_dim_2': 17, 'n_dim_3': 254}. Best is trial 10 with value: 0.5417538783454021.\n",
      "[I 2023-12-07 21:12:33,473] Trial 13 finished with value: 0.03760742459623192 and parameters: {'learning_rate': 0.00023637343154601505, 'batcher': False, 'n_layers': 5, 'n_dim_0': 220, 'n_dim_1': 286, 'n_dim_2': 4, 'n_dim_3': 286}. Best is trial 10 with value: 0.5417538783454021.\n",
      "[I 2023-12-07 21:13:48,756] Trial 14 finished with value: 0.7487066623695531 and parameters: {'learning_rate': 0.009494467210687026, 'batcher': False, 'n_layers': 5, 'n_dim_0': 275, 'n_dim_1': 222, 'n_dim_2': 148, 'n_dim_3': 288}. Best is trial 14 with value: 0.7487066623695531.\n",
      "[I 2023-12-07 21:15:04,916] Trial 15 finished with value: 0.7496387707091695 and parameters: {'learning_rate': 0.008779323565022432, 'batcher': False, 'n_layers': 5, 'n_dim_0': 310, 'n_dim_1': 370, 'n_dim_2': 169, 'n_dim_3': 486}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:16:21,895] Trial 16 finished with value: -7.462769461953359 and parameters: {'learning_rate': 0.00901367782309131, 'batcher': False, 'n_layers': 5, 'n_dim_0': 322, 'n_dim_1': 357, 'n_dim_2': 236, 'n_dim_3': 470}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:17:43,369] Trial 17 finished with value: -20.714766359485687 and parameters: {'learning_rate': 0.00789687046297137, 'batcher': False, 'n_layers': 3, 'n_dim_0': 403, 'n_dim_1': 389}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:19:20,794] Trial 18 finished with value: 0.03313969458648114 and parameters: {'learning_rate': 0.009575614360661323, 'batcher': False, 'n_layers': 5, 'n_dim_0': 305, 'n_dim_1': 288, 'n_dim_2': 153, 'n_dim_3': 503}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:20:34,384] Trial 19 finished with value: -72965.23811523363 and parameters: {'learning_rate': 0.0021211719154125798, 'batcher': False, 'n_layers': 1}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:21:50,131] Trial 20 finished with value: -48.228109930126294 and parameters: {'learning_rate': 0.0050112917625022586, 'batcher': False, 'n_layers': 3, 'n_dim_0': 510, 'n_dim_1': 424}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:23:03,561] Trial 21 finished with value: 0.6347471992180588 and parameters: {'learning_rate': 0.0013211338865803343, 'batcher': False, 'n_layers': 5, 'n_dim_0': 181, 'n_dim_1': 182, 'n_dim_2': 178, 'n_dim_3': 16}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:24:17,110] Trial 22 finished with value: -942.6468974872507 and parameters: {'learning_rate': 0.0057477743663281984, 'batcher': False, 'n_layers': 5, 'n_dim_0': 160, 'n_dim_1': 131, 'n_dim_2': 199, 'n_dim_3': 5}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:25:30,199] Trial 23 finished with value: -1.686415219202366 and parameters: {'learning_rate': 0.002259958363875437, 'batcher': False, 'n_layers': 4, 'n_dim_0': 158, 'n_dim_1': 254, 'n_dim_2': 324}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:26:44,371] Trial 24 finished with value: 0.6770223529766225 and parameters: {'learning_rate': 0.005108520360599949, 'batcher': False, 'n_layers': 5, 'n_dim_0': 359, 'n_dim_1': 169, 'n_dim_2': 320, 'n_dim_3': 18}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:28:27,992] Trial 25 finished with value: -9.929244432534817 and parameters: {'learning_rate': 0.009704618937285935, 'batcher': False, 'n_layers': 4, 'n_dim_0': 380, 'n_dim_1': 342, 'n_dim_2': 327}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:30:18,832] Trial 26 finished with value: 0.7068247118548008 and parameters: {'learning_rate': 0.005009350929484989, 'batcher': False, 'n_layers': 5, 'n_dim_0': 340, 'n_dim_1': 292, 'n_dim_2': 300, 'n_dim_3': 377}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:32:08,822] Trial 27 finished with value: 0.7303051263792129 and parameters: {'learning_rate': 0.0029991959503691454, 'batcher': False, 'n_layers': 5, 'n_dim_0': 296, 'n_dim_1': 302, 'n_dim_2': 81, 'n_dim_3': 389}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:33:56,587] Trial 28 finished with value: -2.225618179073036 and parameters: {'learning_rate': 0.002468819442035082, 'batcher': False, 'n_layers': 4, 'n_dim_0': 281, 'n_dim_1': 421, 'n_dim_2': 89}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:35:42,686] Trial 29 finished with value: -46150.8911453105 and parameters: {'learning_rate': 0.0032125565031751627, 'batcher': False, 'n_layers': 1}. Best is trial 15 with value: 0.7496387707091695.\n",
      "[I 2023-12-07 21:37:36,877] Trial 30 finished with value: 0.7672066914453695 and parameters: {'learning_rate': 0.00551798175244625, 'batcher': False, 'n_layers': 5, 'n_dim_0': 418, 'n_dim_1': 506, 'n_dim_2': 107, 'n_dim_3': 392}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:39:28,675] Trial 31 finished with value: 0.7332882994608514 and parameters: {'learning_rate': 0.0067785600560114736, 'batcher': False, 'n_layers': 5, 'n_dim_0': 429, 'n_dim_1': 469, 'n_dim_2': 97, 'n_dim_3': 409}. Best is trial 30 with value: 0.7672066914453695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 21:41:17,875] Trial 32 finished with value: -5.30462039756285 and parameters: {'learning_rate': 0.006566163561283359, 'batcher': False, 'n_layers': 5, 'n_dim_0': 433, 'n_dim_1': 472, 'n_dim_2': 148, 'n_dim_3': 408}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:43:09,859] Trial 33 finished with value: -989.1997262990868 and parameters: {'learning_rate': 0.009982275827264298, 'batcher': False, 'n_layers': 4, 'n_dim_0': 421, 'n_dim_1': 503, 'n_dim_2': 62}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:45:03,393] Trial 34 finished with value: -0.8994558132579256 and parameters: {'learning_rate': 0.006425253946387897, 'batcher': False, 'n_layers': 5, 'n_dim_0': 481, 'n_dim_1': 456, 'n_dim_2': 201, 'n_dim_3': 452}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:46:49,456] Trial 35 finished with value: -2.2579536308298502 and parameters: {'learning_rate': 0.004202639229411177, 'batcher': False, 'n_layers': 4, 'n_dim_0': 449, 'n_dim_1': 386, 'n_dim_2': 153}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:48:35,592] Trial 36 finished with value: -2.0150704465365346 and parameters: {'learning_rate': 0.006524720362471935, 'batcher': False, 'n_layers': 4, 'n_dim_0': 394, 'n_dim_1': 507, 'n_dim_2': 58}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:50:05,187] Trial 37 finished with value: 0.4624398656011649 and parameters: {'learning_rate': 0.0010067789598073341, 'batcher': True, 'n_layers': 5, 'n_dim_0': 247, 'n_dim_1': 465, 'n_dim_2': 114, 'n_dim_3': 334}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:52:02,342] Trial 38 finished with value: 0.6766530728393241 and parameters: {'learning_rate': 0.0038999244420473344, 'batcher': False, 'n_layers': 5, 'n_dim_0': 335, 'n_dim_1': 380, 'n_dim_2': 187, 'n_dim_3': 188}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:53:21,287] Trial 39 finished with value: -3754.8929212768007 and parameters: {'learning_rate': 0.00180687349493792, 'batcher': True, 'n_layers': 2, 'n_dim_0': 493}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:54:50,474] Trial 40 finished with value: -91.49573836020889 and parameters: {'learning_rate': 0.003620961556485143, 'batcher': False, 'n_layers': 3, 'n_dim_0': 349, 'n_dim_1': 419}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:56:06,995] Trial 41 finished with value: -27.611232064650324 and parameters: {'learning_rate': 0.006847255314914567, 'batcher': False, 'n_layers': 5, 'n_dim_0': 299, 'n_dim_1': 315, 'n_dim_2': 60, 'n_dim_3': 403}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:57:23,291] Trial 42 finished with value: 0.7181867541242469 and parameters: {'learning_rate': 0.003155831430934417, 'batcher': False, 'n_layers': 5, 'n_dim_0': 262, 'n_dim_1': 313, 'n_dim_2': 103, 'n_dim_3': 351}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:58:41,162] Trial 43 finished with value: 0.38379730397729755 and parameters: {'learning_rate': 0.0026296415864940476, 'batcher': False, 'n_layers': 5, 'n_dim_0': 308, 'n_dim_1': 243, 'n_dim_2': 86, 'n_dim_3': 445}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 21:59:56,462] Trial 44 finished with value: 0.29619132942293025 and parameters: {'learning_rate': 0.004432361984334211, 'batcher': True, 'n_layers': 4, 'n_dim_0': 415, 'n_dim_1': 447, 'n_dim_2': 133}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 22:01:13,043] Trial 45 finished with value: -29.42984865021562 and parameters: {'learning_rate': 0.007093300859237536, 'batcher': False, 'n_layers': 4, 'n_dim_0': 369, 'n_dim_1': 482, 'n_dim_2': 501}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 22:02:26,292] Trial 46 finished with value: 0.5842934253881592 and parameters: {'learning_rate': 0.002774144202578332, 'batcher': False, 'n_layers': 5, 'n_dim_0': 247, 'n_dim_1': 360, 'n_dim_2': 78, 'n_dim_3': 320}. Best is trial 30 with value: 0.7672066914453695.\n",
      "[I 2023-12-07 22:03:44,253] Trial 47 finished with value: 0.8265775508851417 and parameters: {'learning_rate': 0.007107275844311816, 'batcher': False, 'n_layers': 5, 'n_dim_0': 453, 'n_dim_1': 222, 'n_dim_2': 41, 'n_dim_3': 506}. Best is trial 47 with value: 0.8265775508851417.\n",
      "[I 2023-12-07 22:04:58,086] Trial 48 finished with value: 0.7659363503131988 and parameters: {'learning_rate': 0.007147504301588226, 'batcher': True, 'n_layers': 5, 'n_dim_0': 446, 'n_dim_1': 93, 'n_dim_2': 36, 'n_dim_3': 512}. Best is trial 47 with value: 0.8265775508851417.\n",
      "[I 2023-12-07 22:06:10,979] Trial 49 finished with value: 0.5858089980101443 and parameters: {'learning_rate': 0.00895157490858688, 'batcher': True, 'n_layers': 5, 'n_dim_0': 465, 'n_dim_1': 84, 'n_dim_2': 45, 'n_dim_3': 510}. Best is trial 47 with value: 0.8265775508851417.\n"
     ]
    }
   ],
   "source": [
    "study_tree = optuna.create_study(study_name=\"Best tree label config\", directions=['maximize'])\n",
    "study_tree.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T02:11:23.313285Z",
     "start_time": "2023-12-07T02:11:23.298286Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.007107275844311816, 'batcher': False, 'n_layers': 5, 'n_dim_0': 453, 'n_dim_1': 222, 'n_dim_2': 41, 'n_dim_3': 506}\n"
     ]
    }
   ],
   "source": [
    "best_par_tree = study_tree.best_params\n",
    "print(best_par_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T02:11:23.358355Z",
     "start_time": "2023-12-07T02:11:23.314287Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPESampler'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_tree.sampler.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T02:11:23.358355Z",
     "start_time": "2023-12-07T02:11:23.330310Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batcher</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_dim_0</th>\n",
       "      <th>params_n_dim_1</th>\n",
       "      <th>params_n_dim_2</th>\n",
       "      <th>params_n_dim_3</th>\n",
       "      <th>params_n_layers</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-210601.946452</td>\n",
       "      <td>2023-12-07 20:55:06.198745</td>\n",
       "      <td>2023-12-07 20:56:21.472785</td>\n",
       "      <td>0 days 00:01:15.274040</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.337820</td>\n",
       "      <td>2023-12-07 20:56:21.474785</td>\n",
       "      <td>2023-12-07 20:57:36.740247</td>\n",
       "      <td>0 days 00:01:15.265462</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>31.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-14.395423</td>\n",
       "      <td>2023-12-07 20:57:36.742584</td>\n",
       "      <td>2023-12-07 20:58:50.586277</td>\n",
       "      <td>0 days 00:01:13.843693</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-25.241747</td>\n",
       "      <td>2023-12-07 20:58:50.588276</td>\n",
       "      <td>2023-12-07 21:00:03.805778</td>\n",
       "      <td>0 days 00:01:13.217502</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>42.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-338.021402</td>\n",
       "      <td>2023-12-07 21:00:03.807736</td>\n",
       "      <td>2023-12-07 21:01:17.091042</td>\n",
       "      <td>0 days 00:01:13.283306</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>66.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>-0.008392</td>\n",
       "      <td>2023-12-07 22:31:15.633734</td>\n",
       "      <td>2023-12-07 22:32:30.223154</td>\n",
       "      <td>0 days 00:01:14.589420</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>-1.638066</td>\n",
       "      <td>2023-12-07 22:32:30.224154</td>\n",
       "      <td>2023-12-07 22:33:45.061230</td>\n",
       "      <td>0 days 00:01:14.837076</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>389.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>-608.274329</td>\n",
       "      <td>2023-12-07 22:33:45.062229</td>\n",
       "      <td>2023-12-07 22:35:01.462536</td>\n",
       "      <td>0 days 00:01:16.400307</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>458.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>-0.017936</td>\n",
       "      <td>2023-12-07 22:35:01.464535</td>\n",
       "      <td>2023-12-07 22:36:16.353428</td>\n",
       "      <td>0 days 00:01:14.888893</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>430.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>-0.055485</td>\n",
       "      <td>2023-12-07 22:36:16.354429</td>\n",
       "      <td>2023-12-07 22:37:33.639262</td>\n",
       "      <td>0 days 00:01:17.284833</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>495.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number          value             datetime_start  \\\n",
       "0        0 -210601.946452 2023-12-07 20:55:06.198745   \n",
       "1        1      -3.337820 2023-12-07 20:56:21.474785   \n",
       "2        2     -14.395423 2023-12-07 20:57:36.742584   \n",
       "3        3     -25.241747 2023-12-07 20:58:50.588276   \n",
       "4        4    -338.021402 2023-12-07 21:00:03.807736   \n",
       "..     ...            ...                        ...   \n",
       "65      65      -0.008392 2023-12-07 22:31:15.633734   \n",
       "66      66      -1.638066 2023-12-07 22:32:30.224154   \n",
       "67      67    -608.274329 2023-12-07 22:33:45.062229   \n",
       "68      68      -0.017936 2023-12-07 22:35:01.464535   \n",
       "69      69      -0.055485 2023-12-07 22:36:16.354429   \n",
       "\n",
       "            datetime_complete               duration  params_batcher  \\\n",
       "0  2023-12-07 20:56:21.472785 0 days 00:01:15.274040           False   \n",
       "1  2023-12-07 20:57:36.740247 0 days 00:01:15.265462            True   \n",
       "2  2023-12-07 20:58:50.586277 0 days 00:01:13.843693            True   \n",
       "3  2023-12-07 21:00:03.805778 0 days 00:01:13.217502            True   \n",
       "4  2023-12-07 21:01:17.091042 0 days 00:01:13.283306            True   \n",
       "..                        ...                    ...             ...   \n",
       "65 2023-12-07 22:32:30.223154 0 days 00:01:14.589420            True   \n",
       "66 2023-12-07 22:33:45.061230 0 days 00:01:14.837076            True   \n",
       "67 2023-12-07 22:35:01.462536 0 days 00:01:16.400307            True   \n",
       "68 2023-12-07 22:36:16.353428 0 days 00:01:14.888893            True   \n",
       "69 2023-12-07 22:37:33.639262 0 days 00:01:17.284833            True   \n",
       "\n",
       "    params_learning_rate  params_n_dim_0  params_n_dim_1  params_n_dim_2  \\\n",
       "0               0.000036             NaN             NaN             NaN   \n",
       "1               0.000934            31.0           144.0           116.0   \n",
       "2               0.000044            25.0            50.0           453.0   \n",
       "3               0.000771            42.0           332.0           405.0   \n",
       "4               0.000094            66.0           437.0             NaN   \n",
       "..                   ...             ...             ...             ...   \n",
       "65              0.007477             5.0            60.0           361.0   \n",
       "66              0.004651           389.0           121.0           262.0   \n",
       "67              0.007462           458.0           163.0           122.0   \n",
       "68              0.005755           430.0           103.0             3.0   \n",
       "69              0.002140           495.0            76.0           103.0   \n",
       "\n",
       "    params_n_dim_3  params_n_layers     state  \n",
       "0              NaN                1  COMPLETE  \n",
       "1              NaN                4  COMPLETE  \n",
       "2              NaN                4  COMPLETE  \n",
       "3              NaN                4  COMPLETE  \n",
       "4              NaN                3  COMPLETE  \n",
       "..             ...              ...       ...  \n",
       "65            91.0                5  COMPLETE  \n",
       "66           166.0                5  COMPLETE  \n",
       "67             NaN                4  COMPLETE  \n",
       "68           463.0                5  COMPLETE  \n",
       "69           512.0                5  COMPLETE  \n",
       "\n",
       "[70 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tree = study_tree.trials_dataframe()\n",
    "df_tree.to_csv(\"study_label-tree_baseline.csv\")\n",
    "display(df_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:17:30.348359Z",
     "end_time": "2023-12-08T08:17:30.354359Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting global parameters\n",
    "dataset_path = \"../../datasets/\"\n",
    "label = \"default\" # alt: tree or default\n",
    "test_perc = 0.3\n",
    "val_perc = 0.21\n",
    "stability_count = 5\n",
    "n_trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:17:34.920905Z",
     "end_time": "2023-12-08T09:33:31.877283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 08:17:34,919] A new study created in memory with name: Best default label config\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44fe421f6fd44cdebb8b82f856f491f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 08:18:53,808] Trial 0 finished with value: -1699.6420836855243 and parameters: {'learning_rate': 0.0004316954260403846, 'batcher': False, 'n_layers': 1}. Best is trial 0 with value: -1699.6420836855243.\n",
      "[I 2023-12-08 08:20:08,280] Trial 1 finished with value: -11.830721453734968 and parameters: {'learning_rate': 1.0187984319561083e-05, 'batcher': True, 'n_layers': 3, 'n_dim_0': 130, 'n_dim_1': 18}. Best is trial 1 with value: -11.830721453734968.\n",
      "[I 2023-12-08 08:21:24,900] Trial 2 finished with value: -48.45359902615071 and parameters: {'learning_rate': 0.0006804323877763095, 'batcher': True, 'n_layers': 2, 'n_dim_0': 118}. Best is trial 1 with value: -11.830721453734968.\n",
      "[I 2023-12-08 08:22:40,923] Trial 3 finished with value: -0.8399402090661099 and parameters: {'learning_rate': 1.5593036116580817e-05, 'batcher': False, 'n_layers': 5, 'n_dim_0': 126, 'n_dim_1': 28, 'n_dim_2': 407, 'n_dim_3': 357}. Best is trial 3 with value: -0.8399402090661099.\n",
      "[I 2023-12-08 08:23:57,188] Trial 4 finished with value: -0.8692137687059347 and parameters: {'learning_rate': 7.972611116807312e-05, 'batcher': True, 'n_layers': 5, 'n_dim_0': 270, 'n_dim_1': 487, 'n_dim_2': 122, 'n_dim_3': 134}. Best is trial 3 with value: -0.8399402090661099.\n",
      "[I 2023-12-08 08:25:12,836] Trial 5 finished with value: -33.51396863570359 and parameters: {'learning_rate': 0.0003700809095907895, 'batcher': True, 'n_layers': 2, 'n_dim_0': 309}. Best is trial 3 with value: -0.8399402090661099.\n",
      "[I 2023-12-08 08:26:29,549] Trial 6 finished with value: -0.46404893715194184 and parameters: {'learning_rate': 0.0013629522005230673, 'batcher': False, 'n_layers': 3, 'n_dim_0': 161, 'n_dim_1': 446}. Best is trial 6 with value: -0.46404893715194184.\n",
      "[I 2023-12-08 08:27:45,259] Trial 7 finished with value: -1917.8383883326533 and parameters: {'learning_rate': 0.00019592570075160077, 'batcher': False, 'n_layers': 1}. Best is trial 6 with value: -0.46404893715194184.\n",
      "[I 2023-12-08 08:28:58,552] Trial 8 finished with value: -258.49788114168894 and parameters: {'learning_rate': 2.0363213012170868e-05, 'batcher': True, 'n_layers': 2, 'n_dim_0': 58}. Best is trial 6 with value: -0.46404893715194184.\n",
      "[I 2023-12-08 08:30:13,925] Trial 9 finished with value: -3.872674423706845 and parameters: {'learning_rate': 3.358140116401902e-05, 'batcher': False, 'n_layers': 3, 'n_dim_0': 391, 'n_dim_1': 207}. Best is trial 6 with value: -0.46404893715194184.\n",
      "[I 2023-12-08 08:31:30,315] Trial 10 finished with value: -0.36086034554376695 and parameters: {'learning_rate': 0.004304073274900673, 'batcher': False, 'n_layers': 4, 'n_dim_0': 438, 'n_dim_1': 496, 'n_dim_2': 512}. Best is trial 10 with value: -0.36086034554376695.\n",
      "[I 2023-12-08 08:32:47,502] Trial 11 finished with value: -0.7930126721354659 and parameters: {'learning_rate': 0.004914260921964607, 'batcher': False, 'n_layers': 4, 'n_dim_0': 507, 'n_dim_1': 511, 'n_dim_2': 488}. Best is trial 10 with value: -0.36086034554376695.\n",
      "[I 2023-12-08 08:34:04,277] Trial 12 finished with value: -0.25749085280215545 and parameters: {'learning_rate': 0.003686016055318863, 'batcher': False, 'n_layers': 4, 'n_dim_0': 496, 'n_dim_1': 374, 'n_dim_2': 274}. Best is trial 12 with value: -0.25749085280215545.\n",
      "[I 2023-12-08 08:35:19,976] Trial 13 finished with value: -0.4116298559594457 and parameters: {'learning_rate': 0.006299159341203603, 'batcher': False, 'n_layers': 4, 'n_dim_0': 504, 'n_dim_1': 343, 'n_dim_2': 273}. Best is trial 12 with value: -0.25749085280215545.\n",
      "[I 2023-12-08 08:36:38,057] Trial 14 finished with value: -0.2634521429515051 and parameters: {'learning_rate': 0.002380017666182924, 'batcher': False, 'n_layers': 4, 'n_dim_0': 424, 'n_dim_1': 345, 'n_dim_2': 31}. Best is trial 12 with value: -0.25749085280215545.\n",
      "[I 2023-12-08 08:37:55,616] Trial 15 finished with value: -0.2721016529402659 and parameters: {'learning_rate': 0.0025078337818325324, 'batcher': False, 'n_layers': 4, 'n_dim_0': 377, 'n_dim_1': 308, 'n_dim_2': 30}. Best is trial 12 with value: -0.25749085280215545.\n",
      "[I 2023-12-08 08:39:14,284] Trial 16 finished with value: -0.302557411739997 and parameters: {'learning_rate': 0.007976251780027343, 'batcher': False, 'n_layers': 5, 'n_dim_0': 425, 'n_dim_1': 202, 'n_dim_2': 232, 'n_dim_3': 512}. Best is trial 12 with value: -0.25749085280215545.\n",
      "[I 2023-12-08 08:40:32,388] Trial 17 finished with value: -0.2813937157821808 and parameters: {'learning_rate': 0.0016855382392469646, 'batcher': False, 'n_layers': 4, 'n_dim_0': 328, 'n_dim_1': 379, 'n_dim_2': 267}. Best is trial 12 with value: -0.25749085280215545.\n",
      "[I 2023-12-08 08:41:47,668] Trial 18 finished with value: -0.2465395990104932 and parameters: {'learning_rate': 0.009284523583274069, 'batcher': False, 'n_layers': 5, 'n_dim_0': 455, 'n_dim_1': 262, 'n_dim_2': 155, 'n_dim_3': 6}. Best is trial 18 with value: -0.2465395990104932.\n",
      "[I 2023-12-08 08:43:00,771] Trial 19 finished with value: -0.7178297647302581 and parameters: {'learning_rate': 0.009801146946803998, 'batcher': False, 'n_layers': 5, 'n_dim_0': 219, 'n_dim_1': 130, 'n_dim_2': 179, 'n_dim_3': 19}. Best is trial 18 with value: -0.2465395990104932.\n",
      "[I 2023-12-08 08:44:17,293] Trial 20 finished with value: -0.2519467155888516 and parameters: {'learning_rate': 0.003507107827791784, 'batcher': False, 'n_layers': 5, 'n_dim_0': 468, 'n_dim_1': 261, 'n_dim_2': 344, 'n_dim_3': 210}. Best is trial 18 with value: -0.2465395990104932.\n",
      "[I 2023-12-08 08:45:34,418] Trial 21 finished with value: -0.2530169980604752 and parameters: {'learning_rate': 0.0033482393411749796, 'batcher': False, 'n_layers': 5, 'n_dim_0': 471, 'n_dim_1': 259, 'n_dim_2': 365, 'n_dim_3': 222}. Best is trial 18 with value: -0.2465395990104932.\n",
      "[I 2023-12-08 08:46:53,122] Trial 22 finished with value: -0.25590527704968824 and parameters: {'learning_rate': 0.001142976966974423, 'batcher': False, 'n_layers': 5, 'n_dim_0': 456, 'n_dim_1': 257, 'n_dim_2': 369, 'n_dim_3': 243}. Best is trial 18 with value: -0.2465395990104932.\n",
      "[I 2023-12-08 08:48:10,713] Trial 23 finished with value: -0.5434283792798402 and parameters: {'learning_rate': 0.008735576232759914, 'batcher': False, 'n_layers': 5, 'n_dim_0': 346, 'n_dim_1': 255, 'n_dim_2': 362, 'n_dim_3': 209}. Best is trial 18 with value: -0.2465395990104932.\n",
      "[I 2023-12-08 08:49:52,750] Trial 24 finished with value: -0.24280282929474328 and parameters: {'learning_rate': 0.0034698025531426594, 'batcher': False, 'n_layers': 5, 'n_dim_0': 459, 'n_dim_1': 143, 'n_dim_2': 342, 'n_dim_3': 8}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 08:51:38,289] Trial 25 finished with value: -129.88498132730746 and parameters: {'learning_rate': 0.0056400028607365, 'batcher': False, 'n_layers': 5, 'n_dim_0': 394, 'n_dim_1': 117, 'n_dim_2': 141, 'n_dim_3': 1}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 08:53:19,851] Trial 26 finished with value: -0.7101976883704905 and parameters: {'learning_rate': 0.0022946245728099114, 'batcher': True, 'n_layers': 5, 'n_dim_0': 274, 'n_dim_1': 133, 'n_dim_2': 435, 'n_dim_3': 90}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 08:55:05,969] Trial 27 finished with value: -0.5271444837415258 and parameters: {'learning_rate': 0.009968568641865405, 'batcher': False, 'n_layers': 3, 'n_dim_0': 365, 'n_dim_1': 184}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 08:56:54,165] Trial 28 finished with value: -0.3044490524819988 and parameters: {'learning_rate': 0.0010703960924158798, 'batcher': False, 'n_layers': 5, 'n_dim_0': 455, 'n_dim_1': 79, 'n_dim_2': 319, 'n_dim_3': 114}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 08:58:40,681] Trial 29 finished with value: -1.0602289435295809 and parameters: {'learning_rate': 0.0007299717223373751, 'batcher': False, 'n_layers': 4, 'n_dim_0': 9, 'n_dim_1': 165, 'n_dim_2': 190}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 09:00:21,166] Trial 30 finished with value: -248.24709719206285 and parameters: {'learning_rate': 0.00522732373735674, 'batcher': False, 'n_layers': 1}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 09:02:00,776] Trial 31 finished with value: -0.28314688224419743 and parameters: {'learning_rate': 0.0032064835942844957, 'batcher': False, 'n_layers': 5, 'n_dim_0': 465, 'n_dim_1': 256, 'n_dim_2': 323, 'n_dim_3': 328}. Best is trial 24 with value: -0.24280282929474328.\n",
      "[I 2023-12-08 09:03:44,357] Trial 32 finished with value: -0.241887005172814 and parameters: {'learning_rate': 0.003675299618197335, 'batcher': False, 'n_layers': 5, 'n_dim_0': 481, 'n_dim_1': 287, 'n_dim_2': 336, 'n_dim_3': 192}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:05:27,550] Trial 33 finished with value: -0.255612306519248 and parameters: {'learning_rate': 0.0019771569657895155, 'batcher': False, 'n_layers': 5, 'n_dim_0': 412, 'n_dim_1': 303, 'n_dim_2': 319, 'n_dim_3': 63}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:07:14,988] Trial 34 finished with value: -0.6554399360598625 and parameters: {'learning_rate': 0.0036729961107078326, 'batcher': True, 'n_layers': 5, 'n_dim_0': 482, 'n_dim_1': 222, 'n_dim_2': 421, 'n_dim_3': 161}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:08:59,691] Trial 35 finished with value: -0.2750034036657513 and parameters: {'learning_rate': 0.006020778653345373, 'batcher': False, 'n_layers': 5, 'n_dim_0': 439, 'n_dim_1': 307, 'n_dim_2': 229, 'n_dim_3': 321}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:10:42,359] Trial 36 finished with value: -0.6436731776844246 and parameters: {'learning_rate': 0.0016943516441665354, 'batcher': True, 'n_layers': 4, 'n_dim_0': 508, 'n_dim_1': 290, 'n_dim_2': 83}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:12:25,109] Trial 37 finished with value: -0.2709056033800154 and parameters: {'learning_rate': 0.0026949351002707404, 'batcher': False, 'n_layers': 5, 'n_dim_0': 214, 'n_dim_1': 229, 'n_dim_2': 312, 'n_dim_3': 170}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:14:09,230] Trial 38 finished with value: -2.409479571914175 and parameters: {'learning_rate': 0.0068195976808128975, 'batcher': False, 'n_layers': 4, 'n_dim_0': 413, 'n_dim_1': 13, 'n_dim_2': 378}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:15:52,094] Trial 39 finished with value: -1.1456118287843375 and parameters: {'learning_rate': 0.0005446988672841798, 'batcher': True, 'n_layers': 5, 'n_dim_0': 303, 'n_dim_1': 158, 'n_dim_2': 204, 'n_dim_3': 49}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:17:36,205] Trial 40 finished with value: -0.8379417972043989 and parameters: {'learning_rate': 0.0037948063453652962, 'batcher': False, 'n_layers': 3, 'n_dim_0': 361, 'n_dim_1': 420}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:19:22,556] Trial 41 finished with value: -0.25912444590713324 and parameters: {'learning_rate': 0.003113122205563947, 'batcher': False, 'n_layers': 5, 'n_dim_0': 477, 'n_dim_1': 269, 'n_dim_2': 349, 'n_dim_3': 254}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:21:09,228] Trial 42 finished with value: -0.2555961139871331 and parameters: {'learning_rate': 0.004352539427980612, 'batcher': False, 'n_layers': 5, 'n_dim_0': 467, 'n_dim_1': 340, 'n_dim_2': 393, 'n_dim_3': 204}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:22:54,833] Trial 43 finished with value: -0.3334847271217588 and parameters: {'learning_rate': 0.006559456102860795, 'batcher': False, 'n_layers': 5, 'n_dim_0': 445, 'n_dim_1': 225, 'n_dim_2': 437, 'n_dim_3': 288}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:24:38,757] Trial 44 finished with value: -39.34978064058329 and parameters: {'learning_rate': 0.00148090486456383, 'batcher': False, 'n_layers': 2, 'n_dim_0': 482}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:26:23,962] Trial 45 finished with value: -0.274925554301631 and parameters: {'learning_rate': 0.004851659140685538, 'batcher': False, 'n_layers': 5, 'n_dim_0': 398, 'n_dim_1': 46, 'n_dim_2': 299, 'n_dim_3': 60}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:28:09,878] Trial 46 finished with value: -0.28649973534001505 and parameters: {'learning_rate': 0.0032831032740679804, 'batcher': False, 'n_layers': 4, 'n_dim_0': 485, 'n_dim_1': 278, 'n_dim_2': 347}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:29:54,311] Trial 47 finished with value: -0.25906584208913197 and parameters: {'learning_rate': 0.002100747668506736, 'batcher': False, 'n_layers': 5, 'n_dim_0': 510, 'n_dim_1': 233, 'n_dim_2': 472, 'n_dim_3': 192}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:31:43,856] Trial 48 finished with value: -0.9940045367272656 and parameters: {'learning_rate': 0.006973515047580271, 'batcher': True, 'n_layers': 4, 'n_dim_0': 439, 'n_dim_1': 321, 'n_dim_2': 403}. Best is trial 32 with value: -0.241887005172814.\n",
      "[I 2023-12-08 09:33:31,861] Trial 49 finished with value: -0.3019197595782053 and parameters: {'learning_rate': 0.004880926681894832, 'batcher': False, 'n_layers': 5, 'n_dim_0': 414, 'n_dim_1': 376, 'n_dim_2': 297, 'n_dim_3': 402}. Best is trial 32 with value: -0.241887005172814.\n"
     ]
    }
   ],
   "source": [
    "study_default = optuna.create_study(study_name=\"Best default label config\", directions=['maximize'])\n",
    "study_default.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T10:07:14.106331Z",
     "end_time": "2023-12-08T10:07:14.135887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.003675299618197335, 'batcher': False, 'n_layers': 5, 'n_dim_0': 481, 'n_dim_1': 287, 'n_dim_2': 336, 'n_dim_3': 192}\n"
     ]
    }
   ],
   "source": [
    "best_par_default = study_default.best_params\n",
    "print(best_par_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T10:07:14.588971Z",
     "end_time": "2023-12-08T10:07:14.627024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'TPESampler'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_default.sampler.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T10:07:15.054042Z",
     "end_time": "2023-12-08T10:07:15.116807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    number        value             datetime_start          datetime_complete  \\\n0        0 -1699.642084 2023-12-08 08:17:34.929904 2023-12-08 08:18:53.808722   \n1        1   -11.830721 2023-12-08 08:18:53.810684 2023-12-08 08:20:08.280544   \n2        2   -48.453599 2023-12-08 08:20:08.282504 2023-12-08 08:21:24.900261   \n3        3    -0.839940 2023-12-08 08:21:24.901261 2023-12-08 08:22:40.922861   \n4        4    -0.869214 2023-12-08 08:22:40.924860 2023-12-08 08:23:57.188800   \n5        5   -33.513969 2023-12-08 08:23:57.189800 2023-12-08 08:25:12.836273   \n6        6    -0.464049 2023-12-08 08:25:12.837272 2023-12-08 08:26:29.549542   \n7        7 -1917.838388 2023-12-08 08:26:29.550542 2023-12-08 08:27:45.259898   \n8        8  -258.497881 2023-12-08 08:27:45.260892 2023-12-08 08:28:58.552896   \n9        9    -3.872674 2023-12-08 08:28:58.553477 2023-12-08 08:30:13.924757   \n10      10    -0.360860 2023-12-08 08:30:13.926756 2023-12-08 08:31:30.315467   \n11      11    -0.793013 2023-12-08 08:31:30.317468 2023-12-08 08:32:47.502141   \n12      12    -0.257491 2023-12-08 08:32:47.503141 2023-12-08 08:34:04.277505   \n13      13    -0.411630 2023-12-08 08:34:04.279465 2023-12-08 08:35:19.976354   \n14      14    -0.263452 2023-12-08 08:35:19.977640 2023-12-08 08:36:38.057540   \n15      15    -0.272102 2023-12-08 08:36:38.059540 2023-12-08 08:37:55.615391   \n16      16    -0.302557 2023-12-08 08:37:55.617391 2023-12-08 08:39:14.283137   \n17      17    -0.281394 2023-12-08 08:39:14.285090 2023-12-08 08:40:32.388231   \n18      18    -0.246540 2023-12-08 08:40:32.389233 2023-12-08 08:41:47.668125   \n19      19    -0.717830 2023-12-08 08:41:47.669126 2023-12-08 08:43:00.771637   \n20      20    -0.251947 2023-12-08 08:43:00.772635 2023-12-08 08:44:17.293232   \n21      21    -0.253017 2023-12-08 08:44:17.294226 2023-12-08 08:45:34.418980   \n22      22    -0.255905 2023-12-08 08:45:34.420980 2023-12-08 08:46:53.122109   \n23      23    -0.543428 2023-12-08 08:46:53.123108 2023-12-08 08:48:10.712087   \n24      24    -0.242803 2023-12-08 08:48:10.714087 2023-12-08 08:49:52.750006   \n25      25  -129.884981 2023-12-08 08:49:52.752005 2023-12-08 08:51:38.289641   \n26      26    -0.710198 2023-12-08 08:51:38.290641 2023-12-08 08:53:19.850863   \n27      27    -0.527144 2023-12-08 08:53:19.852863 2023-12-08 08:55:05.969359   \n28      28    -0.304449 2023-12-08 08:55:05.970358 2023-12-08 08:56:54.165210   \n29      29    -1.060229 2023-12-08 08:56:54.166210 2023-12-08 08:58:40.681411   \n30      30  -248.247097 2023-12-08 08:58:40.682411 2023-12-08 09:00:21.166113   \n31      31    -0.283147 2023-12-08 09:00:21.167112 2023-12-08 09:02:00.776119   \n32      32    -0.241887 2023-12-08 09:02:00.777119 2023-12-08 09:03:44.356188   \n33      33    -0.255612 2023-12-08 09:03:44.358187 2023-12-08 09:05:27.550081   \n34      34    -0.655440 2023-12-08 09:05:27.552081 2023-12-08 09:07:14.988800   \n35      35    -0.275003 2023-12-08 09:07:14.990805 2023-12-08 09:08:59.691711   \n36      36    -0.643673 2023-12-08 09:08:59.693297 2023-12-08 09:10:42.358481   \n37      37    -0.270906 2023-12-08 09:10:42.360481 2023-12-08 09:12:25.108132   \n38      38    -2.409480 2023-12-08 09:12:25.110131 2023-12-08 09:14:09.230827   \n39      39    -1.145612 2023-12-08 09:14:09.231826 2023-12-08 09:15:52.093758   \n40      40    -0.837942 2023-12-08 09:15:52.096760 2023-12-08 09:17:36.204193   \n41      41    -0.259124 2023-12-08 09:17:36.206193 2023-12-08 09:19:22.556455   \n42      42    -0.255596 2023-12-08 09:19:22.558456 2023-12-08 09:21:09.228556   \n43      43    -0.333485 2023-12-08 09:21:09.229556 2023-12-08 09:22:54.833946   \n44      44   -39.349781 2023-12-08 09:22:54.834958 2023-12-08 09:24:38.756607   \n45      45    -0.274926 2023-12-08 09:24:38.758605 2023-12-08 09:26:23.962785   \n46      46    -0.286500 2023-12-08 09:26:23.963787 2023-12-08 09:28:09.877009   \n47      47    -0.259066 2023-12-08 09:28:09.879013 2023-12-08 09:29:54.311179   \n48      48    -0.994005 2023-12-08 09:29:54.312179 2023-12-08 09:31:43.856747   \n49      49    -0.301920 2023-12-08 09:31:43.858748 2023-12-08 09:33:31.861788   \n\n                 duration  params_batcher  params_learning_rate  \\\n0  0 days 00:01:18.878818           False              0.000432   \n1  0 days 00:01:14.469860            True              0.000010   \n2  0 days 00:01:16.617757            True              0.000680   \n3  0 days 00:01:16.021600           False              0.000016   \n4  0 days 00:01:16.263940            True              0.000080   \n5  0 days 00:01:15.646473            True              0.000370   \n6  0 days 00:01:16.712270           False              0.001363   \n7  0 days 00:01:15.709356           False              0.000196   \n8  0 days 00:01:13.292004            True              0.000020   \n9  0 days 00:01:15.371280           False              0.000034   \n10 0 days 00:01:16.388711           False              0.004304   \n11 0 days 00:01:17.184673           False              0.004914   \n12 0 days 00:01:16.774364           False              0.003686   \n13 0 days 00:01:15.696889           False              0.006299   \n14 0 days 00:01:18.079900           False              0.002380   \n15 0 days 00:01:17.555851           False              0.002508   \n16 0 days 00:01:18.665746           False              0.007976   \n17 0 days 00:01:18.103141           False              0.001686   \n18 0 days 00:01:15.278892           False              0.009285   \n19 0 days 00:01:13.102511           False              0.009801   \n20 0 days 00:01:16.520597           False              0.003507   \n21 0 days 00:01:17.124754           False              0.003348   \n22 0 days 00:01:18.701129           False              0.001143   \n23 0 days 00:01:17.588979           False              0.008736   \n24 0 days 00:01:42.035919           False              0.003470   \n25 0 days 00:01:45.537636           False              0.005640   \n26 0 days 00:01:41.560222            True              0.002295   \n27 0 days 00:01:46.116496           False              0.009969   \n28 0 days 00:01:48.194852           False              0.001070   \n29 0 days 00:01:46.515201           False              0.000730   \n30 0 days 00:01:40.483702           False              0.005227   \n31 0 days 00:01:39.609007           False              0.003206   \n32 0 days 00:01:43.579069           False              0.003675   \n33 0 days 00:01:43.191894           False              0.001977   \n34 0 days 00:01:47.436719            True              0.003673   \n35 0 days 00:01:44.700906           False              0.006021   \n36 0 days 00:01:42.665184            True              0.001694   \n37 0 days 00:01:42.747651           False              0.002695   \n38 0 days 00:01:44.120696           False              0.006820   \n39 0 days 00:01:42.861932            True              0.000545   \n40 0 days 00:01:44.107433           False              0.003795   \n41 0 days 00:01:46.350262           False              0.003113   \n42 0 days 00:01:46.670100           False              0.004353   \n43 0 days 00:01:45.604390           False              0.006559   \n44 0 days 00:01:43.921649           False              0.001481   \n45 0 days 00:01:45.204180           False              0.004852   \n46 0 days 00:01:45.913222           False              0.003283   \n47 0 days 00:01:44.432166           False              0.002101   \n48 0 days 00:01:49.544568            True              0.006974   \n49 0 days 00:01:48.003040           False              0.004881   \n\n    params_n_dim_0  params_n_dim_1  params_n_dim_2  params_n_dim_3  \\\n0              NaN             NaN             NaN             NaN   \n1            130.0            18.0             NaN             NaN   \n2            118.0             NaN             NaN             NaN   \n3            126.0            28.0           407.0           357.0   \n4            270.0           487.0           122.0           134.0   \n5            309.0             NaN             NaN             NaN   \n6            161.0           446.0             NaN             NaN   \n7              NaN             NaN             NaN             NaN   \n8             58.0             NaN             NaN             NaN   \n9            391.0           207.0             NaN             NaN   \n10           438.0           496.0           512.0             NaN   \n11           507.0           511.0           488.0             NaN   \n12           496.0           374.0           274.0             NaN   \n13           504.0           343.0           273.0             NaN   \n14           424.0           345.0            31.0             NaN   \n15           377.0           308.0            30.0             NaN   \n16           425.0           202.0           232.0           512.0   \n17           328.0           379.0           267.0             NaN   \n18           455.0           262.0           155.0             6.0   \n19           219.0           130.0           179.0            19.0   \n20           468.0           261.0           344.0           210.0   \n21           471.0           259.0           365.0           222.0   \n22           456.0           257.0           369.0           243.0   \n23           346.0           255.0           362.0           209.0   \n24           459.0           143.0           342.0             8.0   \n25           394.0           117.0           141.0             1.0   \n26           274.0           133.0           435.0            90.0   \n27           365.0           184.0             NaN             NaN   \n28           455.0            79.0           319.0           114.0   \n29             9.0           165.0           190.0             NaN   \n30             NaN             NaN             NaN             NaN   \n31           465.0           256.0           323.0           328.0   \n32           481.0           287.0           336.0           192.0   \n33           412.0           303.0           319.0            63.0   \n34           482.0           222.0           421.0           161.0   \n35           439.0           307.0           229.0           321.0   \n36           508.0           290.0            83.0             NaN   \n37           214.0           229.0           312.0           170.0   \n38           413.0            13.0           378.0             NaN   \n39           303.0           158.0           204.0            49.0   \n40           361.0           420.0             NaN             NaN   \n41           477.0           269.0           349.0           254.0   \n42           467.0           340.0           393.0           204.0   \n43           445.0           225.0           437.0           288.0   \n44           482.0             NaN             NaN             NaN   \n45           398.0            46.0           299.0            60.0   \n46           485.0           278.0           347.0             NaN   \n47           510.0           233.0           472.0           192.0   \n48           439.0           321.0           403.0             NaN   \n49           414.0           376.0           297.0           402.0   \n\n    params_n_layers     state  \n0                 1  COMPLETE  \n1                 3  COMPLETE  \n2                 2  COMPLETE  \n3                 5  COMPLETE  \n4                 5  COMPLETE  \n5                 2  COMPLETE  \n6                 3  COMPLETE  \n7                 1  COMPLETE  \n8                 2  COMPLETE  \n9                 3  COMPLETE  \n10                4  COMPLETE  \n11                4  COMPLETE  \n12                4  COMPLETE  \n13                4  COMPLETE  \n14                4  COMPLETE  \n15                4  COMPLETE  \n16                5  COMPLETE  \n17                4  COMPLETE  \n18                5  COMPLETE  \n19                5  COMPLETE  \n20                5  COMPLETE  \n21                5  COMPLETE  \n22                5  COMPLETE  \n23                5  COMPLETE  \n24                5  COMPLETE  \n25                5  COMPLETE  \n26                5  COMPLETE  \n27                3  COMPLETE  \n28                5  COMPLETE  \n29                4  COMPLETE  \n30                1  COMPLETE  \n31                5  COMPLETE  \n32                5  COMPLETE  \n33                5  COMPLETE  \n34                5  COMPLETE  \n35                5  COMPLETE  \n36                4  COMPLETE  \n37                5  COMPLETE  \n38                4  COMPLETE  \n39                5  COMPLETE  \n40                3  COMPLETE  \n41                5  COMPLETE  \n42                5  COMPLETE  \n43                5  COMPLETE  \n44                2  COMPLETE  \n45                5  COMPLETE  \n46                4  COMPLETE  \n47                5  COMPLETE  \n48                4  COMPLETE  \n49                5  COMPLETE  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_batcher</th>\n      <th>params_learning_rate</th>\n      <th>params_n_dim_0</th>\n      <th>params_n_dim_1</th>\n      <th>params_n_dim_2</th>\n      <th>params_n_dim_3</th>\n      <th>params_n_layers</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-1699.642084</td>\n      <td>2023-12-08 08:17:34.929904</td>\n      <td>2023-12-08 08:18:53.808722</td>\n      <td>0 days 00:01:18.878818</td>\n      <td>False</td>\n      <td>0.000432</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-11.830721</td>\n      <td>2023-12-08 08:18:53.810684</td>\n      <td>2023-12-08 08:20:08.280544</td>\n      <td>0 days 00:01:14.469860</td>\n      <td>True</td>\n      <td>0.000010</td>\n      <td>130.0</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-48.453599</td>\n      <td>2023-12-08 08:20:08.282504</td>\n      <td>2023-12-08 08:21:24.900261</td>\n      <td>0 days 00:01:16.617757</td>\n      <td>True</td>\n      <td>0.000680</td>\n      <td>118.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-0.839940</td>\n      <td>2023-12-08 08:21:24.901261</td>\n      <td>2023-12-08 08:22:40.922861</td>\n      <td>0 days 00:01:16.021600</td>\n      <td>False</td>\n      <td>0.000016</td>\n      <td>126.0</td>\n      <td>28.0</td>\n      <td>407.0</td>\n      <td>357.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-0.869214</td>\n      <td>2023-12-08 08:22:40.924860</td>\n      <td>2023-12-08 08:23:57.188800</td>\n      <td>0 days 00:01:16.263940</td>\n      <td>True</td>\n      <td>0.000080</td>\n      <td>270.0</td>\n      <td>487.0</td>\n      <td>122.0</td>\n      <td>134.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>-33.513969</td>\n      <td>2023-12-08 08:23:57.189800</td>\n      <td>2023-12-08 08:25:12.836273</td>\n      <td>0 days 00:01:15.646473</td>\n      <td>True</td>\n      <td>0.000370</td>\n      <td>309.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>-0.464049</td>\n      <td>2023-12-08 08:25:12.837272</td>\n      <td>2023-12-08 08:26:29.549542</td>\n      <td>0 days 00:01:16.712270</td>\n      <td>False</td>\n      <td>0.001363</td>\n      <td>161.0</td>\n      <td>446.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>-1917.838388</td>\n      <td>2023-12-08 08:26:29.550542</td>\n      <td>2023-12-08 08:27:45.259898</td>\n      <td>0 days 00:01:15.709356</td>\n      <td>False</td>\n      <td>0.000196</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>-258.497881</td>\n      <td>2023-12-08 08:27:45.260892</td>\n      <td>2023-12-08 08:28:58.552896</td>\n      <td>0 days 00:01:13.292004</td>\n      <td>True</td>\n      <td>0.000020</td>\n      <td>58.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>-3.872674</td>\n      <td>2023-12-08 08:28:58.553477</td>\n      <td>2023-12-08 08:30:13.924757</td>\n      <td>0 days 00:01:15.371280</td>\n      <td>False</td>\n      <td>0.000034</td>\n      <td>391.0</td>\n      <td>207.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>-0.360860</td>\n      <td>2023-12-08 08:30:13.926756</td>\n      <td>2023-12-08 08:31:30.315467</td>\n      <td>0 days 00:01:16.388711</td>\n      <td>False</td>\n      <td>0.004304</td>\n      <td>438.0</td>\n      <td>496.0</td>\n      <td>512.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>-0.793013</td>\n      <td>2023-12-08 08:31:30.317468</td>\n      <td>2023-12-08 08:32:47.502141</td>\n      <td>0 days 00:01:17.184673</td>\n      <td>False</td>\n      <td>0.004914</td>\n      <td>507.0</td>\n      <td>511.0</td>\n      <td>488.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>-0.257491</td>\n      <td>2023-12-08 08:32:47.503141</td>\n      <td>2023-12-08 08:34:04.277505</td>\n      <td>0 days 00:01:16.774364</td>\n      <td>False</td>\n      <td>0.003686</td>\n      <td>496.0</td>\n      <td>374.0</td>\n      <td>274.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>-0.411630</td>\n      <td>2023-12-08 08:34:04.279465</td>\n      <td>2023-12-08 08:35:19.976354</td>\n      <td>0 days 00:01:15.696889</td>\n      <td>False</td>\n      <td>0.006299</td>\n      <td>504.0</td>\n      <td>343.0</td>\n      <td>273.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>-0.263452</td>\n      <td>2023-12-08 08:35:19.977640</td>\n      <td>2023-12-08 08:36:38.057540</td>\n      <td>0 days 00:01:18.079900</td>\n      <td>False</td>\n      <td>0.002380</td>\n      <td>424.0</td>\n      <td>345.0</td>\n      <td>31.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>-0.272102</td>\n      <td>2023-12-08 08:36:38.059540</td>\n      <td>2023-12-08 08:37:55.615391</td>\n      <td>0 days 00:01:17.555851</td>\n      <td>False</td>\n      <td>0.002508</td>\n      <td>377.0</td>\n      <td>308.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>-0.302557</td>\n      <td>2023-12-08 08:37:55.617391</td>\n      <td>2023-12-08 08:39:14.283137</td>\n      <td>0 days 00:01:18.665746</td>\n      <td>False</td>\n      <td>0.007976</td>\n      <td>425.0</td>\n      <td>202.0</td>\n      <td>232.0</td>\n      <td>512.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>-0.281394</td>\n      <td>2023-12-08 08:39:14.285090</td>\n      <td>2023-12-08 08:40:32.388231</td>\n      <td>0 days 00:01:18.103141</td>\n      <td>False</td>\n      <td>0.001686</td>\n      <td>328.0</td>\n      <td>379.0</td>\n      <td>267.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>-0.246540</td>\n      <td>2023-12-08 08:40:32.389233</td>\n      <td>2023-12-08 08:41:47.668125</td>\n      <td>0 days 00:01:15.278892</td>\n      <td>False</td>\n      <td>0.009285</td>\n      <td>455.0</td>\n      <td>262.0</td>\n      <td>155.0</td>\n      <td>6.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>-0.717830</td>\n      <td>2023-12-08 08:41:47.669126</td>\n      <td>2023-12-08 08:43:00.771637</td>\n      <td>0 days 00:01:13.102511</td>\n      <td>False</td>\n      <td>0.009801</td>\n      <td>219.0</td>\n      <td>130.0</td>\n      <td>179.0</td>\n      <td>19.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>-0.251947</td>\n      <td>2023-12-08 08:43:00.772635</td>\n      <td>2023-12-08 08:44:17.293232</td>\n      <td>0 days 00:01:16.520597</td>\n      <td>False</td>\n      <td>0.003507</td>\n      <td>468.0</td>\n      <td>261.0</td>\n      <td>344.0</td>\n      <td>210.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>-0.253017</td>\n      <td>2023-12-08 08:44:17.294226</td>\n      <td>2023-12-08 08:45:34.418980</td>\n      <td>0 days 00:01:17.124754</td>\n      <td>False</td>\n      <td>0.003348</td>\n      <td>471.0</td>\n      <td>259.0</td>\n      <td>365.0</td>\n      <td>222.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>-0.255905</td>\n      <td>2023-12-08 08:45:34.420980</td>\n      <td>2023-12-08 08:46:53.122109</td>\n      <td>0 days 00:01:18.701129</td>\n      <td>False</td>\n      <td>0.001143</td>\n      <td>456.0</td>\n      <td>257.0</td>\n      <td>369.0</td>\n      <td>243.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>-0.543428</td>\n      <td>2023-12-08 08:46:53.123108</td>\n      <td>2023-12-08 08:48:10.712087</td>\n      <td>0 days 00:01:17.588979</td>\n      <td>False</td>\n      <td>0.008736</td>\n      <td>346.0</td>\n      <td>255.0</td>\n      <td>362.0</td>\n      <td>209.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>-0.242803</td>\n      <td>2023-12-08 08:48:10.714087</td>\n      <td>2023-12-08 08:49:52.750006</td>\n      <td>0 days 00:01:42.035919</td>\n      <td>False</td>\n      <td>0.003470</td>\n      <td>459.0</td>\n      <td>143.0</td>\n      <td>342.0</td>\n      <td>8.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>-129.884981</td>\n      <td>2023-12-08 08:49:52.752005</td>\n      <td>2023-12-08 08:51:38.289641</td>\n      <td>0 days 00:01:45.537636</td>\n      <td>False</td>\n      <td>0.005640</td>\n      <td>394.0</td>\n      <td>117.0</td>\n      <td>141.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>-0.710198</td>\n      <td>2023-12-08 08:51:38.290641</td>\n      <td>2023-12-08 08:53:19.850863</td>\n      <td>0 days 00:01:41.560222</td>\n      <td>True</td>\n      <td>0.002295</td>\n      <td>274.0</td>\n      <td>133.0</td>\n      <td>435.0</td>\n      <td>90.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>-0.527144</td>\n      <td>2023-12-08 08:53:19.852863</td>\n      <td>2023-12-08 08:55:05.969359</td>\n      <td>0 days 00:01:46.116496</td>\n      <td>False</td>\n      <td>0.009969</td>\n      <td>365.0</td>\n      <td>184.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>-0.304449</td>\n      <td>2023-12-08 08:55:05.970358</td>\n      <td>2023-12-08 08:56:54.165210</td>\n      <td>0 days 00:01:48.194852</td>\n      <td>False</td>\n      <td>0.001070</td>\n      <td>455.0</td>\n      <td>79.0</td>\n      <td>319.0</td>\n      <td>114.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>-1.060229</td>\n      <td>2023-12-08 08:56:54.166210</td>\n      <td>2023-12-08 08:58:40.681411</td>\n      <td>0 days 00:01:46.515201</td>\n      <td>False</td>\n      <td>0.000730</td>\n      <td>9.0</td>\n      <td>165.0</td>\n      <td>190.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>-248.247097</td>\n      <td>2023-12-08 08:58:40.682411</td>\n      <td>2023-12-08 09:00:21.166113</td>\n      <td>0 days 00:01:40.483702</td>\n      <td>False</td>\n      <td>0.005227</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>-0.283147</td>\n      <td>2023-12-08 09:00:21.167112</td>\n      <td>2023-12-08 09:02:00.776119</td>\n      <td>0 days 00:01:39.609007</td>\n      <td>False</td>\n      <td>0.003206</td>\n      <td>465.0</td>\n      <td>256.0</td>\n      <td>323.0</td>\n      <td>328.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>-0.241887</td>\n      <td>2023-12-08 09:02:00.777119</td>\n      <td>2023-12-08 09:03:44.356188</td>\n      <td>0 days 00:01:43.579069</td>\n      <td>False</td>\n      <td>0.003675</td>\n      <td>481.0</td>\n      <td>287.0</td>\n      <td>336.0</td>\n      <td>192.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>-0.255612</td>\n      <td>2023-12-08 09:03:44.358187</td>\n      <td>2023-12-08 09:05:27.550081</td>\n      <td>0 days 00:01:43.191894</td>\n      <td>False</td>\n      <td>0.001977</td>\n      <td>412.0</td>\n      <td>303.0</td>\n      <td>319.0</td>\n      <td>63.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>-0.655440</td>\n      <td>2023-12-08 09:05:27.552081</td>\n      <td>2023-12-08 09:07:14.988800</td>\n      <td>0 days 00:01:47.436719</td>\n      <td>True</td>\n      <td>0.003673</td>\n      <td>482.0</td>\n      <td>222.0</td>\n      <td>421.0</td>\n      <td>161.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>-0.275003</td>\n      <td>2023-12-08 09:07:14.990805</td>\n      <td>2023-12-08 09:08:59.691711</td>\n      <td>0 days 00:01:44.700906</td>\n      <td>False</td>\n      <td>0.006021</td>\n      <td>439.0</td>\n      <td>307.0</td>\n      <td>229.0</td>\n      <td>321.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>-0.643673</td>\n      <td>2023-12-08 09:08:59.693297</td>\n      <td>2023-12-08 09:10:42.358481</td>\n      <td>0 days 00:01:42.665184</td>\n      <td>True</td>\n      <td>0.001694</td>\n      <td>508.0</td>\n      <td>290.0</td>\n      <td>83.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>-0.270906</td>\n      <td>2023-12-08 09:10:42.360481</td>\n      <td>2023-12-08 09:12:25.108132</td>\n      <td>0 days 00:01:42.747651</td>\n      <td>False</td>\n      <td>0.002695</td>\n      <td>214.0</td>\n      <td>229.0</td>\n      <td>312.0</td>\n      <td>170.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>-2.409480</td>\n      <td>2023-12-08 09:12:25.110131</td>\n      <td>2023-12-08 09:14:09.230827</td>\n      <td>0 days 00:01:44.120696</td>\n      <td>False</td>\n      <td>0.006820</td>\n      <td>413.0</td>\n      <td>13.0</td>\n      <td>378.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>-1.145612</td>\n      <td>2023-12-08 09:14:09.231826</td>\n      <td>2023-12-08 09:15:52.093758</td>\n      <td>0 days 00:01:42.861932</td>\n      <td>True</td>\n      <td>0.000545</td>\n      <td>303.0</td>\n      <td>158.0</td>\n      <td>204.0</td>\n      <td>49.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>-0.837942</td>\n      <td>2023-12-08 09:15:52.096760</td>\n      <td>2023-12-08 09:17:36.204193</td>\n      <td>0 days 00:01:44.107433</td>\n      <td>False</td>\n      <td>0.003795</td>\n      <td>361.0</td>\n      <td>420.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>-0.259124</td>\n      <td>2023-12-08 09:17:36.206193</td>\n      <td>2023-12-08 09:19:22.556455</td>\n      <td>0 days 00:01:46.350262</td>\n      <td>False</td>\n      <td>0.003113</td>\n      <td>477.0</td>\n      <td>269.0</td>\n      <td>349.0</td>\n      <td>254.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>-0.255596</td>\n      <td>2023-12-08 09:19:22.558456</td>\n      <td>2023-12-08 09:21:09.228556</td>\n      <td>0 days 00:01:46.670100</td>\n      <td>False</td>\n      <td>0.004353</td>\n      <td>467.0</td>\n      <td>340.0</td>\n      <td>393.0</td>\n      <td>204.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>-0.333485</td>\n      <td>2023-12-08 09:21:09.229556</td>\n      <td>2023-12-08 09:22:54.833946</td>\n      <td>0 days 00:01:45.604390</td>\n      <td>False</td>\n      <td>0.006559</td>\n      <td>445.0</td>\n      <td>225.0</td>\n      <td>437.0</td>\n      <td>288.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>-39.349781</td>\n      <td>2023-12-08 09:22:54.834958</td>\n      <td>2023-12-08 09:24:38.756607</td>\n      <td>0 days 00:01:43.921649</td>\n      <td>False</td>\n      <td>0.001481</td>\n      <td>482.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>-0.274926</td>\n      <td>2023-12-08 09:24:38.758605</td>\n      <td>2023-12-08 09:26:23.962785</td>\n      <td>0 days 00:01:45.204180</td>\n      <td>False</td>\n      <td>0.004852</td>\n      <td>398.0</td>\n      <td>46.0</td>\n      <td>299.0</td>\n      <td>60.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>-0.286500</td>\n      <td>2023-12-08 09:26:23.963787</td>\n      <td>2023-12-08 09:28:09.877009</td>\n      <td>0 days 00:01:45.913222</td>\n      <td>False</td>\n      <td>0.003283</td>\n      <td>485.0</td>\n      <td>278.0</td>\n      <td>347.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>-0.259066</td>\n      <td>2023-12-08 09:28:09.879013</td>\n      <td>2023-12-08 09:29:54.311179</td>\n      <td>0 days 00:01:44.432166</td>\n      <td>False</td>\n      <td>0.002101</td>\n      <td>510.0</td>\n      <td>233.0</td>\n      <td>472.0</td>\n      <td>192.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>-0.994005</td>\n      <td>2023-12-08 09:29:54.312179</td>\n      <td>2023-12-08 09:31:43.856747</td>\n      <td>0 days 00:01:49.544568</td>\n      <td>True</td>\n      <td>0.006974</td>\n      <td>439.0</td>\n      <td>321.0</td>\n      <td>403.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>-0.301920</td>\n      <td>2023-12-08 09:31:43.858748</td>\n      <td>2023-12-08 09:33:31.861788</td>\n      <td>0 days 00:01:48.003040</td>\n      <td>False</td>\n      <td>0.004881</td>\n      <td>414.0</td>\n      <td>376.0</td>\n      <td>297.0</td>\n      <td>402.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_default = study_default.trials_dataframe()\n",
    "df_default.to_csv(\"study_label-default_baseline.csv\")\n",
    "display(df_default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
