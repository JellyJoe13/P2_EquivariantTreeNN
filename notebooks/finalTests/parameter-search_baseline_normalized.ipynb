{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter search with optuna - BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T19:56:47.706480Z",
     "end_time": "2023-12-08T19:56:49.711723Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from etnn import TreeNode\n",
    "from etnn.nn.layer_framework import LayerManagementFramework\n",
    "from etnn.routines.run_config import choice_dataset, choice_trainloader, choice_loss, choice_optim\n",
    "from etnn.tools.training import train_epoch, eval_epoch\n",
    "from etnn.tools.training_tools import ConfigStore, seeding_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of objective function for ETNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T19:56:49.708717Z",
     "end_time": "2023-12-08T19:56:49.725234Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # init default config\n",
    "    config = ConfigStore(\n",
    "        in_dim=15,\n",
    "        hidden_dim=0, #trial.suggest_int(\"hidden_dim\", 16, 512, step=16),\n",
    "        out_dim=1,\n",
    "        k=0, #trial.suggest_int(\"k\", 1, 5),\n",
    "        dataset=-1,\n",
    "        ds_size=10_000,\n",
    "        num_gondolas=10,\n",
    "        num_part_pg=5,\n",
    "        loss_name='mse',\n",
    "        optimizer_name='adam',\n",
    "        num_max_epochs=30, # real: 100\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True),\n",
    "        batch_size=1024,\n",
    "        early_stop_tol=5,\n",
    "        use_equal_batcher=trial.suggest_categorical(\"batcher\", [True, False]),\n",
    "        seed=420,\n",
    "        label_type=label,\n",
    "        final_label_factor=1/1000\n",
    "    )\n",
    "\n",
    "    # loading dataset\n",
    "    dataset, df_index = choice_dataset(config, dataset_path)\n",
    "    # splitting off test dataset\n",
    "    generator = torch.Generator().manual_seed(config.seed)\n",
    "    train_ds, val_ds, _ = random_split(\n",
    "        dataset,\n",
    "        [1 - test_perc - val_perc, val_perc, test_perc],\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    # loaders\n",
    "    train_loader = choice_trainloader(config, df_index, train_ds)\n",
    "    val_loader = DataLoader(val_ds, batch_size=4 * config.batch_size, shuffle=False)\n",
    "\n",
    "    # build tree\n",
    "    tree_structure = TreeNode(\n",
    "        node_type=\"C\",\n",
    "        children=[\n",
    "            TreeNode(\"P\", [TreeNode(\"E\", config.num_part_pg)])\n",
    "            for _ in range(config.num_gondolas)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # define device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # set seed for reproducability\n",
    "    seeding_all(config.seed)\n",
    "\n",
    "    # define model\n",
    "    layer_list = [torch.nn.Flatten()]\n",
    "    features = config.in_dim * config.num_gondolas * config.num_part_pg\n",
    "\n",
    "    # for each layer create a linear layer and relu (except last one)\n",
    "    for i in range(trial.suggest_int(\"n_layers\", 1, 5)-1):\n",
    "        # determine new feature dimension\n",
    "        new_features = trial.suggest_int(f\"n_dim_{i}\", 1, 512)\n",
    "\n",
    "        # add layer and relu to list\n",
    "        layer_list += [torch.nn.Linear(features, new_features), torch.nn.ReLU()]\n",
    "\n",
    "        # set the new feature to be the current feature\n",
    "        features = new_features\n",
    "\n",
    "    # set the last layer - this one must map to the out dimension\n",
    "    layer_list += [torch.nn.Linear(features, config.out_dim)]\n",
    "    model = torch.nn.Sequential(*layer_list).to(device)\n",
    "\n",
    "    # learning tools\n",
    "    criterion = choice_loss(config)\n",
    "    optimizer = choice_optim(config, model)\n",
    "\n",
    "    # init score list\n",
    "    score_list = []\n",
    "\n",
    "    # train for specified number of epochs\n",
    "    for epoch in range(config.num_max_epochs):\n",
    "        _, _, _ = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            device,\n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        _, val_true_y, val_pred_y = eval_epoch(\n",
    "            model,\n",
    "            val_loader,\n",
    "            device,\n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        # calc r2 score and append\n",
    "        score = r2_score(y_true=val_true_y, y_pred=val_pred_y)\n",
    "        score_list += [score]\n",
    "        trial.report(score, epoch)\n",
    "\n",
    "    # calculate objective\n",
    "    # display(score_list)\n",
    "    # idea: last x r2 scores (why not last one? for stability purposes)\n",
    "    obj = np.array(score_list)[-stability_count:]\n",
    "    return np.mean(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree advanced label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T19:56:49.719229Z",
     "end_time": "2023-12-08T19:56:49.738248Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting global parameters\n",
    "dataset_path = \"../../datasets/\"\n",
    "label = \"tree_advanced\" # alt: tree or default\n",
    "test_perc = 0.3\n",
    "val_perc = 0.21\n",
    "stability_count = 5\n",
    "n_trials = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T19:56:49.734747Z",
     "end_time": "2023-12-08T21:20:08.701550Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 19:56:49,734] A new study created in memory with name: Best tree advanced label config\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ccaf819cb0e49e1ae2aee4e06ed078e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 19:57:58,943] Trial 0 finished with value: -939.4449011030545 and parameters: {'learning_rate': 2.4006605088264315e-05, 'batcher': False, 'n_layers': 1}. Best is trial 0 with value: -939.4449011030545.\n",
      "[I 2023-12-08 19:59:19,023] Trial 1 finished with value: 0.9201144923544472 and parameters: {'learning_rate': 0.002104284711699982, 'batcher': False, 'n_layers': 4, 'n_dim_0': 219, 'n_dim_1': 401, 'n_dim_2': 355}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:00:40,962] Trial 2 finished with value: -1004.7290627621171 and parameters: {'learning_rate': 3.064636911462103e-05, 'batcher': False, 'n_layers': 5, 'n_dim_0': 89, 'n_dim_1': 304, 'n_dim_2': 315, 'n_dim_3': 1}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:02:05,508] Trial 3 finished with value: 0.8962070188960141 and parameters: {'learning_rate': 0.00029349149611142326, 'batcher': False, 'n_layers': 2, 'n_dim_0': 208}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:03:23,213] Trial 4 finished with value: 0.9055881370849903 and parameters: {'learning_rate': 0.0007282096147110321, 'batcher': True, 'n_layers': 2, 'n_dim_0': 250}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:04:44,712] Trial 5 finished with value: -993.624634550896 and parameters: {'learning_rate': 1.1311738324281564e-05, 'batcher': False, 'n_layers': 4, 'n_dim_0': 290, 'n_dim_1': 4, 'n_dim_2': 124}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:06:09,097] Trial 6 finished with value: -465.6051316576466 and parameters: {'learning_rate': 4.089666520723408e-05, 'batcher': False, 'n_layers': 4, 'n_dim_0': 10, 'n_dim_1': 306, 'n_dim_2': 481}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:07:29,723] Trial 7 finished with value: 0.8485639115971821 and parameters: {'learning_rate': 0.000131484746754946, 'batcher': False, 'n_layers': 3, 'n_dim_0': 234, 'n_dim_1': 113}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:08:49,208] Trial 8 finished with value: 0.6371897439994275 and parameters: {'learning_rate': 0.00010105382081448794, 'batcher': False, 'n_layers': 5, 'n_dim_0': 21, 'n_dim_1': 408, 'n_dim_2': 106, 'n_dim_3': 321}. Best is trial 1 with value: 0.9201144923544472.\n",
      "[I 2023-12-08 20:10:12,048] Trial 9 finished with value: 0.9298934646097419 and parameters: {'learning_rate': 0.0021640628309100973, 'batcher': False, 'n_layers': 3, 'n_dim_0': 300, 'n_dim_1': 170}. Best is trial 9 with value: 0.9298934646097419.\n",
      "[I 2023-12-08 20:11:25,546] Trial 10 finished with value: 0.939308391074331 and parameters: {'learning_rate': 0.006810065904661181, 'batcher': True, 'n_layers': 3, 'n_dim_0': 492, 'n_dim_1': 151}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:12:43,790] Trial 11 finished with value: 0.9126776964599028 and parameters: {'learning_rate': 0.007335143865807707, 'batcher': True, 'n_layers': 3, 'n_dim_0': 512, 'n_dim_1': 144}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:14:07,974] Trial 12 finished with value: 0.9258175994473129 and parameters: {'learning_rate': 0.008634350702532705, 'batcher': True, 'n_layers': 2, 'n_dim_0': 501}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:15:29,367] Trial 13 finished with value: 0.9339033673525897 and parameters: {'learning_rate': 0.002305902761577434, 'batcher': True, 'n_layers': 3, 'n_dim_0': 376, 'n_dim_1': 173}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:16:52,627] Trial 14 finished with value: 0.8371002559445596 and parameters: {'learning_rate': 0.003248121941145798, 'batcher': True, 'n_layers': 1}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:18:17,919] Trial 15 finished with value: 0.9014414043379565 and parameters: {'learning_rate': 0.0008565111539130362, 'batcher': True, 'n_layers': 2, 'n_dim_0': 405}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:19:46,620] Trial 16 finished with value: 0.933645010618085 and parameters: {'learning_rate': 0.004376516836814639, 'batcher': True, 'n_layers': 4, 'n_dim_0': 405, 'n_dim_1': 202, 'n_dim_2': 7}. Best is trial 10 with value: 0.939308391074331.\n",
      "[I 2023-12-08 20:21:13,501] Trial 17 finished with value: 0.9579897192771221 and parameters: {'learning_rate': 0.00949924946536999, 'batcher': True, 'n_layers': 3, 'n_dim_0': 408, 'n_dim_1': 49}. Best is trial 17 with value: 0.9579897192771221.\n",
      "[I 2023-12-08 20:22:37,896] Trial 18 finished with value: 0.9407069163061085 and parameters: {'learning_rate': 0.009645617348184962, 'batcher': True, 'n_layers': 3, 'n_dim_0': 454, 'n_dim_1': 28}. Best is trial 17 with value: 0.9579897192771221.\n",
      "[I 2023-12-08 20:23:44,097] Trial 19 finished with value: 0.9644312023521735 and parameters: {'learning_rate': 0.008466422572167911, 'batcher': True, 'n_layers': 4, 'n_dim_0': 353, 'n_dim_1': 7, 'n_dim_2': 484}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:24:48,313] Trial 20 finished with value: 0.913752896172982 and parameters: {'learning_rate': 0.001352962385907345, 'batcher': True, 'n_layers': 5, 'n_dim_0': 342, 'n_dim_1': 70, 'n_dim_2': 487, 'n_dim_3': 483}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:25:53,679] Trial 21 finished with value: 0.9260372462564831 and parameters: {'learning_rate': 0.009084596244391166, 'batcher': True, 'n_layers': 4, 'n_dim_0': 442, 'n_dim_1': 8, 'n_dim_2': 387}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:26:58,311] Trial 22 finished with value: 0.9493676934382214 and parameters: {'learning_rate': 0.004264048908737209, 'batcher': True, 'n_layers': 4, 'n_dim_0': 433, 'n_dim_1': 69, 'n_dim_2': 242}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:28:03,292] Trial 23 finished with value: 0.9350138597220065 and parameters: {'learning_rate': 0.003939209439550552, 'batcher': True, 'n_layers': 4, 'n_dim_0': 345, 'n_dim_1': 77, 'n_dim_2': 226}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:29:08,187] Trial 24 finished with value: 0.9292304199889626 and parameters: {'learning_rate': 0.004936838880993335, 'batcher': True, 'n_layers': 5, 'n_dim_0': 433, 'n_dim_1': 72, 'n_dim_2': 231, 'n_dim_3': 19}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:30:11,228] Trial 25 finished with value: 0.9386613848508476 and parameters: {'learning_rate': 0.003694798812389439, 'batcher': True, 'n_layers': 4, 'n_dim_0': 339, 'n_dim_1': 223, 'n_dim_2': 164}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:31:13,541] Trial 26 finished with value: 0.9209501390116273 and parameters: {'learning_rate': 0.005855660600003501, 'batcher': True, 'n_layers': 4, 'n_dim_0': 394, 'n_dim_1': 68, 'n_dim_2': 422}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:32:29,134] Trial 27 finished with value: 0.8903487036898821 and parameters: {'learning_rate': 0.0011312910329665349, 'batcher': True, 'n_layers': 5, 'n_dim_0': 162, 'n_dim_1': 492, 'n_dim_2': 301, 'n_dim_3': 219}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:33:38,233] Trial 28 finished with value: 0.9158249102204771 and parameters: {'learning_rate': 0.005649250885136129, 'batcher': True, 'n_layers': 4, 'n_dim_0': 293, 'n_dim_1': 101, 'n_dim_2': 272}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:34:38,756] Trial 29 finished with value: 0.8632748630248426 and parameters: {'learning_rate': 0.009727147668432579, 'batcher': True, 'n_layers': 1}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:35:41,142] Trial 30 finished with value: 0.9269484892311001 and parameters: {'learning_rate': 0.0028696278560047324, 'batcher': True, 'n_layers': 3, 'n_dim_0': 460, 'n_dim_1': 33}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:36:43,185] Trial 31 finished with value: 0.9471680201084693 and parameters: {'learning_rate': 0.009744117606332267, 'batcher': True, 'n_layers': 3, 'n_dim_0': 452, 'n_dim_1': 29}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:37:44,497] Trial 32 finished with value: 0.936504448817457 and parameters: {'learning_rate': 0.005258790065671598, 'batcher': True, 'n_layers': 3, 'n_dim_0': 374, 'n_dim_1': 42}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:38:46,274] Trial 33 finished with value: 0.9316339644760653 and parameters: {'learning_rate': 0.0030601912282606967, 'batcher': True, 'n_layers': 3, 'n_dim_0': 475, 'n_dim_1': 113}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:39:48,320] Trial 34 finished with value: 0.918931861048647 and parameters: {'learning_rate': 0.0016960436985858178, 'batcher': True, 'n_layers': 2, 'n_dim_0': 413}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:40:50,873] Trial 35 finished with value: 0.933303415558765 and parameters: {'learning_rate': 0.006197729785092861, 'batcher': True, 'n_layers': 4, 'n_dim_0': 359, 'n_dim_1': 6, 'n_dim_2': 184}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:42:05,276] Trial 36 finished with value: 0.9510954839661515 and parameters: {'learning_rate': 0.009750329810546953, 'batcher': True, 'n_layers': 2, 'n_dim_0': 433}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:43:07,448] Trial 37 finished with value: 0.9329203790126386 and parameters: {'learning_rate': 0.004306233412929154, 'batcher': True, 'n_layers': 2, 'n_dim_0': 314}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:44:09,837] Trial 38 finished with value: 0.8367455839560185 and parameters: {'learning_rate': 0.0024149644799878163, 'batcher': False, 'n_layers': 1}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:45:12,110] Trial 39 finished with value: 0.8903655082640007 and parameters: {'learning_rate': 0.00048282096525936014, 'batcher': True, 'n_layers': 2, 'n_dim_0': 196}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:46:16,276] Trial 40 finished with value: 0.9223327712212246 and parameters: {'learning_rate': 0.0018330274495553574, 'batcher': False, 'n_layers': 5, 'n_dim_0': 267, 'n_dim_1': 277, 'n_dim_2': 61, 'n_dim_3': 481}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:47:21,256] Trial 41 finished with value: 0.9225520905232324 and parameters: {'learning_rate': 0.009983098192843832, 'batcher': True, 'n_layers': 3, 'n_dim_0': 431, 'n_dim_1': 49}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:48:25,490] Trial 42 finished with value: 0.9432786198089282 and parameters: {'learning_rate': 0.006690925968317369, 'batcher': True, 'n_layers': 2, 'n_dim_0': 467}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:49:29,475] Trial 43 finished with value: 0.9449682497355081 and parameters: {'learning_rate': 0.006817193921378128, 'batcher': True, 'n_layers': 3, 'n_dim_0': 427, 'n_dim_1': 105}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:50:33,489] Trial 44 finished with value: 0.9273426187161439 and parameters: {'learning_rate': 0.004751945407738815, 'batcher': True, 'n_layers': 4, 'n_dim_0': 386, 'n_dim_1': 36, 'n_dim_2': 450}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:51:42,705] Trial 45 finished with value: 0.9463485814839651 and parameters: {'learning_rate': 0.006804174894193472, 'batcher': False, 'n_layers': 3, 'n_dim_0': 478, 'n_dim_1': 2}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:53:01,048] Trial 46 finished with value: 0.922930934762723 and parameters: {'learning_rate': 0.0035434556911161223, 'batcher': True, 'n_layers': 4, 'n_dim_0': 318, 'n_dim_1': 128, 'n_dim_2': 357}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:54:04,716] Trial 47 finished with value: 0.9531950401763737 and parameters: {'learning_rate': 0.007341340042405144, 'batcher': True, 'n_layers': 3, 'n_dim_0': 421, 'n_dim_1': 83}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:55:17,437] Trial 48 finished with value: 0.9277897327529987 and parameters: {'learning_rate': 0.002501628247537146, 'batcher': False, 'n_layers': 2, 'n_dim_0': 373}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:56:23,173] Trial 49 finished with value: 0.9182492560245666 and parameters: {'learning_rate': 0.007366392845944377, 'batcher': True, 'n_layers': 4, 'n_dim_0': 64, 'n_dim_1': 86, 'n_dim_2': 190}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:57:26,527] Trial 50 finished with value: 0.8431844899871933 and parameters: {'learning_rate': 0.004717900374040663, 'batcher': True, 'n_layers': 1}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:58:31,482] Trial 51 finished with value: 0.9515136437270121 and parameters: {'learning_rate': 0.007815579563335564, 'batcher': True, 'n_layers': 3, 'n_dim_0': 426, 'n_dim_1': 54}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 20:59:36,995] Trial 52 finished with value: 0.9555405188504622 and parameters: {'learning_rate': 0.008014696688191457, 'batcher': True, 'n_layers': 3, 'n_dim_0': 414, 'n_dim_1': 58}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:00:42,203] Trial 53 finished with value: 0.9522257159835877 and parameters: {'learning_rate': 0.007916508559622823, 'batcher': True, 'n_layers': 3, 'n_dim_0': 412, 'n_dim_1': 339}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:01:46,784] Trial 54 finished with value: 0.9076583233057225 and parameters: {'learning_rate': 0.00707129359545054, 'batcher': True, 'n_layers': 3, 'n_dim_0': 414, 'n_dim_1': 342}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:02:49,385] Trial 55 finished with value: 0.9419107095566295 and parameters: {'learning_rate': 0.0032327663425095288, 'batcher': True, 'n_layers': 3, 'n_dim_0': 397, 'n_dim_1': 361}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:04:03,868] Trial 56 finished with value: 0.9263613426464536 and parameters: {'learning_rate': 0.008176769148566139, 'batcher': True, 'n_layers': 3, 'n_dim_0': 488, 'n_dim_1': 394}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:05:23,252] Trial 57 finished with value: 0.9372328392377993 and parameters: {'learning_rate': 0.005520320767696093, 'batcher': True, 'n_layers': 3, 'n_dim_0': 361, 'n_dim_1': 463}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:06:43,300] Trial 58 finished with value: 0.9325296908836649 and parameters: {'learning_rate': 0.004003670206439472, 'batcher': True, 'n_layers': 3, 'n_dim_0': 411, 'n_dim_1': 308}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:07:59,605] Trial 59 finished with value: 0.9228185735630141 and parameters: {'learning_rate': 0.008264514954164463, 'batcher': False, 'n_layers': 3, 'n_dim_0': 326, 'n_dim_1': 233}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:09:09,805] Trial 60 finished with value: 0.9537553843514635 and parameters: {'learning_rate': 0.005243961094356972, 'batcher': True, 'n_layers': 3, 'n_dim_0': 512, 'n_dim_1': 178}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:10:21,379] Trial 61 finished with value: 0.9254871203957284 and parameters: {'learning_rate': 0.006096213441445701, 'batcher': True, 'n_layers': 3, 'n_dim_0': 505, 'n_dim_1': 177}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:11:35,220] Trial 62 finished with value: 0.910466308837964 and parameters: {'learning_rate': 0.007704307967957096, 'batcher': True, 'n_layers': 3, 'n_dim_0': 456, 'n_dim_1': 129}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:12:47,922] Trial 63 finished with value: 0.9339642385703808 and parameters: {'learning_rate': 0.0050640533381528935, 'batcher': True, 'n_layers': 3, 'n_dim_0': 396, 'n_dim_1': 52}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:14:01,702] Trial 64 finished with value: 0.9120379622668737 and parameters: {'learning_rate': 0.008125407956984911, 'batcher': True, 'n_layers': 3, 'n_dim_0': 512, 'n_dim_1': 87}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:15:14,487] Trial 65 finished with value: 0.9397059948982877 and parameters: {'learning_rate': 0.003786625404393997, 'batcher': True, 'n_layers': 3, 'n_dim_0': 360, 'n_dim_1': 153}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:16:23,830] Trial 66 finished with value: 0.9449775465605048 and parameters: {'learning_rate': 0.005395549051098949, 'batcher': True, 'n_layers': 3, 'n_dim_0': 446, 'n_dim_1': 56}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:17:36,604] Trial 67 finished with value: 0.9315768994598578 and parameters: {'learning_rate': 0.007961295281468127, 'batcher': True, 'n_layers': 3, 'n_dim_0': 485, 'n_dim_1': 19}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:18:54,545] Trial 68 finished with value: 0.9233583532922527 and parameters: {'learning_rate': 0.005930743866591937, 'batcher': True, 'n_layers': 3, 'n_dim_0': 387, 'n_dim_1': 262}. Best is trial 19 with value: 0.9644312023521735.\n",
      "[I 2023-12-08 21:20:08,694] Trial 69 finished with value: 0.9342570207689084 and parameters: {'learning_rate': 0.0029441143553212415, 'batcher': True, 'n_layers': 3, 'n_dim_0': 423, 'n_dim_1': 203}. Best is trial 19 with value: 0.9644312023521735.\n"
     ]
    }
   ],
   "source": [
    "study_tree_advanced = optuna.create_study(study_name=\"Best tree advanced label config\", directions=['maximize'])\n",
    "study_tree_advanced.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T21:20:08.703530Z",
     "end_time": "2023-12-08T21:20:08.718529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.008466422572167911, 'batcher': True, 'n_layers': 4, 'n_dim_0': 353, 'n_dim_1': 7, 'n_dim_2': 484}\n"
     ]
    }
   ],
   "source": [
    "best_par_tree_advanced = study_tree_advanced.best_params\n",
    "print(best_par_tree_advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T21:20:08.718529Z",
     "end_time": "2023-12-08T21:20:08.744530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'TPESampler'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_tree_advanced.sampler.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T21:20:08.735529Z",
     "end_time": "2023-12-08T21:20:08.771531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    number        value             datetime_start          datetime_complete  \\\n0        0  -939.444901 2023-12-08 19:56:49.744254 2023-12-08 19:57:58.943975   \n1        1     0.920114 2023-12-08 19:57:58.945480 2023-12-08 19:59:19.023901   \n2        2 -1004.729063 2023-12-08 19:59:19.025902 2023-12-08 20:00:40.961248   \n3        3     0.896207 2023-12-08 20:00:40.963248 2023-12-08 20:02:05.507228   \n4        4     0.905588 2023-12-08 20:02:05.509229 2023-12-08 20:03:23.213526   \n..     ...          ...                        ...                        ...   \n65      65     0.939706 2023-12-08 21:14:01.704534 2023-12-08 21:15:14.487481   \n66      66     0.944978 2023-12-08 21:15:14.488480 2023-12-08 21:16:23.830428   \n67      67     0.931577 2023-12-08 21:16:23.832429 2023-12-08 21:17:36.604296   \n68      68     0.923358 2023-12-08 21:17:36.605310 2023-12-08 21:18:54.544129   \n69      69     0.934257 2023-12-08 21:18:54.546128 2023-12-08 21:20:08.693019   \n\n                 duration  params_batcher  params_learning_rate  \\\n0  0 days 00:01:09.199721           False              0.000024   \n1  0 days 00:01:20.078421           False              0.002104   \n2  0 days 00:01:21.935346           False              0.000031   \n3  0 days 00:01:24.543980           False              0.000293   \n4  0 days 00:01:17.704297            True              0.000728   \n..                    ...             ...                   ...   \n65 0 days 00:01:12.782947            True              0.003787   \n66 0 days 00:01:09.341948            True              0.005396   \n67 0 days 00:01:12.771867            True              0.007961   \n68 0 days 00:01:17.938819            True              0.005931   \n69 0 days 00:01:14.146891            True              0.002944   \n\n    params_n_dim_0  params_n_dim_1  params_n_dim_2  params_n_dim_3  \\\n0              NaN             NaN             NaN             NaN   \n1            219.0           401.0           355.0             NaN   \n2             89.0           304.0           315.0             1.0   \n3            208.0             NaN             NaN             NaN   \n4            250.0             NaN             NaN             NaN   \n..             ...             ...             ...             ...   \n65           360.0           153.0             NaN             NaN   \n66           446.0            56.0             NaN             NaN   \n67           485.0            19.0             NaN             NaN   \n68           387.0           262.0             NaN             NaN   \n69           423.0           203.0             NaN             NaN   \n\n    params_n_layers     state  \n0                 1  COMPLETE  \n1                 4  COMPLETE  \n2                 5  COMPLETE  \n3                 2  COMPLETE  \n4                 2  COMPLETE  \n..              ...       ...  \n65                3  COMPLETE  \n66                3  COMPLETE  \n67                3  COMPLETE  \n68                3  COMPLETE  \n69                3  COMPLETE  \n\n[70 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_batcher</th>\n      <th>params_learning_rate</th>\n      <th>params_n_dim_0</th>\n      <th>params_n_dim_1</th>\n      <th>params_n_dim_2</th>\n      <th>params_n_dim_3</th>\n      <th>params_n_layers</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-939.444901</td>\n      <td>2023-12-08 19:56:49.744254</td>\n      <td>2023-12-08 19:57:58.943975</td>\n      <td>0 days 00:01:09.199721</td>\n      <td>False</td>\n      <td>0.000024</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.920114</td>\n      <td>2023-12-08 19:57:58.945480</td>\n      <td>2023-12-08 19:59:19.023901</td>\n      <td>0 days 00:01:20.078421</td>\n      <td>False</td>\n      <td>0.002104</td>\n      <td>219.0</td>\n      <td>401.0</td>\n      <td>355.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-1004.729063</td>\n      <td>2023-12-08 19:59:19.025902</td>\n      <td>2023-12-08 20:00:40.961248</td>\n      <td>0 days 00:01:21.935346</td>\n      <td>False</td>\n      <td>0.000031</td>\n      <td>89.0</td>\n      <td>304.0</td>\n      <td>315.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.896207</td>\n      <td>2023-12-08 20:00:40.963248</td>\n      <td>2023-12-08 20:02:05.507228</td>\n      <td>0 days 00:01:24.543980</td>\n      <td>False</td>\n      <td>0.000293</td>\n      <td>208.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.905588</td>\n      <td>2023-12-08 20:02:05.509229</td>\n      <td>2023-12-08 20:03:23.213526</td>\n      <td>0 days 00:01:17.704297</td>\n      <td>True</td>\n      <td>0.000728</td>\n      <td>250.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>65</td>\n      <td>0.939706</td>\n      <td>2023-12-08 21:14:01.704534</td>\n      <td>2023-12-08 21:15:14.487481</td>\n      <td>0 days 00:01:12.782947</td>\n      <td>True</td>\n      <td>0.003787</td>\n      <td>360.0</td>\n      <td>153.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>66</td>\n      <td>0.944978</td>\n      <td>2023-12-08 21:15:14.488480</td>\n      <td>2023-12-08 21:16:23.830428</td>\n      <td>0 days 00:01:09.341948</td>\n      <td>True</td>\n      <td>0.005396</td>\n      <td>446.0</td>\n      <td>56.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>67</td>\n      <td>0.931577</td>\n      <td>2023-12-08 21:16:23.832429</td>\n      <td>2023-12-08 21:17:36.604296</td>\n      <td>0 days 00:01:12.771867</td>\n      <td>True</td>\n      <td>0.007961</td>\n      <td>485.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>68</td>\n      <td>0.923358</td>\n      <td>2023-12-08 21:17:36.605310</td>\n      <td>2023-12-08 21:18:54.544129</td>\n      <td>0 days 00:01:17.938819</td>\n      <td>True</td>\n      <td>0.005931</td>\n      <td>387.0</td>\n      <td>262.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>69</td>\n      <td>0.934257</td>\n      <td>2023-12-08 21:18:54.546128</td>\n      <td>2023-12-08 21:20:08.693019</td>\n      <td>0 days 00:01:14.146891</td>\n      <td>True</td>\n      <td>0.002944</td>\n      <td>423.0</td>\n      <td>203.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tree_advanced = study_tree_advanced.trials_dataframe()\n",
    "df_tree_advanced.to_csv(\"study_label-tree-advanced_baseline_normalized.csv\")\n",
    "display(df_tree_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T21:20:08.766529Z",
     "end_time": "2023-12-08T21:20:08.782530Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting global parameters\n",
    "dataset_path = \"../../datasets/\"\n",
    "label = \"tree\" # alt: tree or default\n",
    "test_perc = 0.3\n",
    "val_perc = 0.21\n",
    "stability_count = 5\n",
    "n_trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T21:20:08.783536Z",
     "end_time": "2023-12-08T22:22:45.605945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:20:08,783] A new study created in memory with name: Best tree label config\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f291eec091e141ff88950bb42f3cdf72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:21:18,473] Trial 0 finished with value: 0.8660064817618178 and parameters: {'learning_rate': 0.008646976968890727, 'batcher': True, 'n_layers': 4, 'n_dim_0': 181, 'n_dim_1': 132, 'n_dim_2': 125}. Best is trial 0 with value: 0.8660064817618178.\n",
      "[I 2023-12-08 21:22:29,376] Trial 1 finished with value: 0.7972039692698816 and parameters: {'learning_rate': 0.0006975641348274792, 'batcher': False, 'n_layers': 2, 'n_dim_0': 190}. Best is trial 0 with value: 0.8660064817618178.\n",
      "[I 2023-12-08 21:23:45,153] Trial 2 finished with value: 0.8130472632062355 and parameters: {'learning_rate': 0.004318543004301319, 'batcher': False, 'n_layers': 4, 'n_dim_0': 403, 'n_dim_1': 324, 'n_dim_2': 495}. Best is trial 0 with value: 0.8660064817618178.\n",
      "[I 2023-12-08 21:25:01,064] Trial 3 finished with value: 0.8875302762419887 and parameters: {'learning_rate': 0.0065806054377971785, 'batcher': False, 'n_layers': 4, 'n_dim_0': 274, 'n_dim_1': 11, 'n_dim_2': 427}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:26:13,470] Trial 4 finished with value: 0.7653639896593778 and parameters: {'learning_rate': 0.00017938501619613588, 'batcher': False, 'n_layers': 2, 'n_dim_0': 441}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:27:22,298] Trial 5 finished with value: -749.3154666033421 and parameters: {'learning_rate': 4.275881027213853e-05, 'batcher': True, 'n_layers': 1}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:28:35,023] Trial 6 finished with value: -245.4494115070927 and parameters: {'learning_rate': 2.2964017509466786e-05, 'batcher': False, 'n_layers': 5, 'n_dim_0': 219, 'n_dim_1': 420, 'n_dim_2': 163, 'n_dim_3': 378}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:29:48,098] Trial 7 finished with value: -643.6817541292614 and parameters: {'learning_rate': 7.163439557395948e-05, 'batcher': True, 'n_layers': 1}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:31:05,536] Trial 8 finished with value: -740.8464017342378 and parameters: {'learning_rate': 1.1455493247549336e-05, 'batcher': True, 'n_layers': 3, 'n_dim_0': 494, 'n_dim_1': 42}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:32:21,574] Trial 9 finished with value: 0.7498971271412808 and parameters: {'learning_rate': 0.00020010964855159027, 'batcher': False, 'n_layers': 5, 'n_dim_0': 257, 'n_dim_1': 185, 'n_dim_2': 423, 'n_dim_3': 352}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:33:29,973] Trial 10 finished with value: -13.468859057212592 and parameters: {'learning_rate': 0.001378000053196894, 'batcher': False, 'n_layers': 4, 'n_dim_0': 15, 'n_dim_1': 1, 'n_dim_2': 331}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:34:43,950] Trial 11 finished with value: 0.8376388853319415 and parameters: {'learning_rate': 0.009355943529528161, 'batcher': True, 'n_layers': 4, 'n_dim_0': 111, 'n_dim_1': 145, 'n_dim_2': 33}. Best is trial 3 with value: 0.8875302762419887.\n",
      "[I 2023-12-08 21:35:55,972] Trial 12 finished with value: 0.9316672875257372 and parameters: {'learning_rate': 0.009597949948171597, 'batcher': True, 'n_layers': 3, 'n_dim_0': 330, 'n_dim_1': 134}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:37:12,130] Trial 13 finished with value: 0.8512660454236375 and parameters: {'learning_rate': 0.0025503169112210387, 'batcher': True, 'n_layers': 3, 'n_dim_0': 334, 'n_dim_1': 85}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:38:25,001] Trial 14 finished with value: 0.8544525231214634 and parameters: {'learning_rate': 0.0028246605406092094, 'batcher': True, 'n_layers': 2, 'n_dim_0': 308}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:39:33,694] Trial 15 finished with value: 0.8215245567879768 and parameters: {'learning_rate': 0.0008924376014309771, 'batcher': False, 'n_layers': 3, 'n_dim_0': 361, 'n_dim_1': 255}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:40:46,712] Trial 16 finished with value: -0.02952984674332195 and parameters: {'learning_rate': 0.009498797951972634, 'batcher': False, 'n_layers': 5, 'n_dim_0': 298, 'n_dim_1': 227, 'n_dim_2': 314, 'n_dim_3': 5}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:42:04,906] Trial 17 finished with value: 0.8463153515891646 and parameters: {'learning_rate': 0.004230360330164057, 'batcher': True, 'n_layers': 4, 'n_dim_0': 118, 'n_dim_1': 85, 'n_dim_2': 510}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:43:25,486] Trial 18 finished with value: 0.7986807445107313 and parameters: {'learning_rate': 0.0004539642557904489, 'batcher': True, 'n_layers': 3, 'n_dim_0': 377, 'n_dim_1': 10}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:44:40,632] Trial 19 finished with value: 0.8442258988124319 and parameters: {'learning_rate': 0.001914696048546327, 'batcher': False, 'n_layers': 2, 'n_dim_0': 271}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:45:53,613] Trial 20 finished with value: 0.8247846543333246 and parameters: {'learning_rate': 0.004302872439388049, 'batcher': False, 'n_layers': 4, 'n_dim_0': 457, 'n_dim_1': 319, 'n_dim_2': 365}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:47:08,808] Trial 21 finished with value: 0.9107669221514028 and parameters: {'learning_rate': 0.008958742348806602, 'batcher': True, 'n_layers': 3, 'n_dim_0': 175, 'n_dim_1': 142}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:48:26,826] Trial 22 finished with value: 0.8698265197969896 and parameters: {'learning_rate': 0.006455324674279224, 'batcher': True, 'n_layers': 3, 'n_dim_0': 154, 'n_dim_1': 122}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:49:43,662] Trial 23 finished with value: 0.8875355773585124 and parameters: {'learning_rate': 0.004485402332447493, 'batcher': True, 'n_layers': 3, 'n_dim_0': 216, 'n_dim_1': 193}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:50:55,312] Trial 24 finished with value: 0.8013505255000701 and parameters: {'learning_rate': 0.0015341093999875028, 'batcher': True, 'n_layers': 2, 'n_dim_0': 76}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:52:06,602] Trial 25 finished with value: 0.8641225065736036 and parameters: {'learning_rate': 0.0033734055091471033, 'batcher': True, 'n_layers': 3, 'n_dim_0': 224, 'n_dim_1': 192}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:53:21,133] Trial 26 finished with value: 0.9214525780247683 and parameters: {'learning_rate': 0.005500655120765626, 'batcher': True, 'n_layers': 3, 'n_dim_0': 228, 'n_dim_1': 299}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:54:38,921] Trial 27 finished with value: 0.8187360385530351 and parameters: {'learning_rate': 0.009711086154697434, 'batcher': True, 'n_layers': 3, 'n_dim_0': 150, 'n_dim_1': 309}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:55:53,216] Trial 28 finished with value: 0.805996393021905 and parameters: {'learning_rate': 0.0022320721805015775, 'batcher': True, 'n_layers': 2, 'n_dim_0': 66}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:57:02,905] Trial 29 finished with value: 0.7272776169979844 and parameters: {'learning_rate': 0.006366991604464243, 'batcher': True, 'n_layers': 3, 'n_dim_0': 325, 'n_dim_1': 437}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:58:09,876] Trial 30 finished with value: 0.8778308077072545 and parameters: {'learning_rate': 0.006128885066374874, 'batcher': True, 'n_layers': 2, 'n_dim_0': 238}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 21:59:21,568] Trial 31 finished with value: 0.8671148351925633 and parameters: {'learning_rate': 0.004192536512273394, 'batcher': True, 'n_layers': 3, 'n_dim_0': 202, 'n_dim_1': 214}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:00:38,178] Trial 32 finished with value: 0.8731955328211012 and parameters: {'learning_rate': 0.00588180883173212, 'batcher': True, 'n_layers': 3, 'n_dim_0': 159, 'n_dim_1': 279}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:01:56,233] Trial 33 finished with value: 0.8558483827933575 and parameters: {'learning_rate': 0.0027800419350980086, 'batcher': True, 'n_layers': 3, 'n_dim_0': 187, 'n_dim_1': 362}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:03:07,607] Trial 34 finished with value: -0.4022025013211592 and parameters: {'learning_rate': 0.009354669600719083, 'batcher': True, 'n_layers': 4, 'n_dim_0': 252, 'n_dim_1': 512, 'n_dim_2': 211}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:04:20,411] Trial 35 finished with value: 0.8636711806113617 and parameters: {'learning_rate': 0.0043115938724538755, 'batcher': True, 'n_layers': 2, 'n_dim_0': 184}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:05:38,502] Trial 36 finished with value: 0.8666020983688792 and parameters: {'learning_rate': 0.006279216202454316, 'batcher': True, 'n_layers': 4, 'n_dim_0': 280, 'n_dim_1': 153, 'n_dim_2': 8}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:07:00,850] Trial 37 finished with value: 0.8105286473700758 and parameters: {'learning_rate': 0.001126985634811343, 'batcher': True, 'n_layers': 3, 'n_dim_0': 354, 'n_dim_1': 87}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:08:15,189] Trial 38 finished with value: 0.8399701542829696 and parameters: {'learning_rate': 0.0018242558543701017, 'batcher': True, 'n_layers': 2, 'n_dim_0': 399}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:09:27,022] Trial 39 finished with value: 0.714965527821289 and parameters: {'learning_rate': 0.0032095274047959192, 'batcher': True, 'n_layers': 1}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:10:44,378] Trial 40 finished with value: 0.7948044003186773 and parameters: {'learning_rate': 0.0007347180589119973, 'batcher': True, 'n_layers': 3, 'n_dim_0': 118, 'n_dim_1': 174}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:12:04,288] Trial 41 finished with value: 0.8259883900199199 and parameters: {'learning_rate': 0.0067015717431284485, 'batcher': False, 'n_layers': 4, 'n_dim_0': 213, 'n_dim_1': 233, 'n_dim_2': 397}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:13:15,338] Trial 42 finished with value: 0.9037227561567516 and parameters: {'learning_rate': 0.005309755466557232, 'batcher': False, 'n_layers': 4, 'n_dim_0': 278, 'n_dim_1': 50, 'n_dim_2': 270}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:14:31,523] Trial 43 finished with value: 0.8914420673097968 and parameters: {'learning_rate': 0.004431201938464726, 'batcher': False, 'n_layers': 4, 'n_dim_0': 294, 'n_dim_1': 117, 'n_dim_2': 258}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:15:45,127] Trial 44 finished with value: 0.8928757011042885 and parameters: {'learning_rate': 0.00732762054529174, 'batcher': False, 'n_layers': 5, 'n_dim_0': 302, 'n_dim_1': 116, 'n_dim_2': 263, 'n_dim_3': 90}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:17:02,027] Trial 45 finished with value: -0.0027699545269123773 and parameters: {'learning_rate': 0.009969177659117843, 'batcher': False, 'n_layers': 5, 'n_dim_0': 326, 'n_dim_1': 67, 'n_dim_2': 257, 'n_dim_3': 81}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:18:21,891] Trial 46 finished with value: 0.8129870627893844 and parameters: {'learning_rate': 0.007524371964446023, 'batcher': False, 'n_layers': 5, 'n_dim_0': 256, 'n_dim_1': 47, 'n_dim_2': 106, 'n_dim_3': 181}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:19:49,093] Trial 47 finished with value: 0.8500315576286693 and parameters: {'learning_rate': 0.0020165858943795275, 'batcher': False, 'n_layers': 5, 'n_dim_0': 416, 'n_dim_1': 107, 'n_dim_2': 199, 'n_dim_3': 174}. Best is trial 12 with value: 0.9316672875257372.\n",
      "[I 2023-12-08 22:21:17,553] Trial 48 finished with value: 0.9496958645762505 and parameters: {'learning_rate': 0.007698706581726475, 'batcher': False, 'n_layers': 4, 'n_dim_0': 344, 'n_dim_1': 50, 'n_dim_2': 294}. Best is trial 48 with value: 0.9496958645762505.\n",
      "[I 2023-12-08 22:22:45,587] Trial 49 finished with value: 0.8668898136524434 and parameters: {'learning_rate': 0.00312245126763305, 'batcher': False, 'n_layers': 4, 'n_dim_0': 381, 'n_dim_1': 40, 'n_dim_2': 309}. Best is trial 48 with value: 0.9496958645762505.\n"
     ]
    }
   ],
   "source": [
    "study_tree = optuna.create_study(study_name=\"Best tree label config\", directions=['maximize'])\n",
    "study_tree.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T22:22:45.609952Z",
     "end_time": "2023-12-08T22:22:45.625364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.007698706581726475, 'batcher': False, 'n_layers': 4, 'n_dim_0': 344, 'n_dim_1': 50, 'n_dim_2': 294}\n"
     ]
    }
   ],
   "source": [
    "best_par_tree = study_tree.best_params\n",
    "print(best_par_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T22:22:45.622190Z",
     "end_time": "2023-12-08T22:22:45.646806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'TPESampler'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_tree.sampler.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T22:22:45.638361Z",
     "end_time": "2023-12-08T22:22:45.674285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    number       value             datetime_start          datetime_complete  \\\n0        0    0.866006 2023-12-08 21:20:08.788536 2023-12-08 21:21:18.473993   \n1        1    0.797204 2023-12-08 21:21:18.474991 2023-12-08 21:22:29.376470   \n2        2    0.813047 2023-12-08 21:22:29.377470 2023-12-08 21:23:45.153962   \n3        3    0.887530 2023-12-08 21:23:45.154963 2023-12-08 21:25:01.064178   \n4        4    0.765364 2023-12-08 21:25:01.065169 2023-12-08 21:26:13.469076   \n5        5 -749.315467 2023-12-08 21:26:13.471076 2023-12-08 21:27:22.298319   \n6        6 -245.449412 2023-12-08 21:27:22.299318 2023-12-08 21:28:35.022163   \n7        7 -643.681754 2023-12-08 21:28:35.024373 2023-12-08 21:29:48.098389   \n8        8 -740.846402 2023-12-08 21:29:48.099388 2023-12-08 21:31:05.536873   \n9        9    0.749897 2023-12-08 21:31:05.537872 2023-12-08 21:32:21.574676   \n10      10  -13.468859 2023-12-08 21:32:21.575638 2023-12-08 21:33:29.972476   \n11      11    0.837639 2023-12-08 21:33:29.974478 2023-12-08 21:34:43.950472   \n12      12    0.931667 2023-12-08 21:34:43.951475 2023-12-08 21:35:55.972492   \n13      13    0.851266 2023-12-08 21:35:55.973489 2023-12-08 21:37:12.130260   \n14      14    0.854453 2023-12-08 21:37:12.132261 2023-12-08 21:38:25.001637   \n15      15    0.821525 2023-12-08 21:38:25.002635 2023-12-08 21:39:33.694643   \n16      16   -0.029530 2023-12-08 21:39:33.696640 2023-12-08 21:40:46.712801   \n17      17    0.846315 2023-12-08 21:40:46.713801 2023-12-08 21:42:04.906719   \n18      18    0.798681 2023-12-08 21:42:04.907719 2023-12-08 21:43:25.486499   \n19      19    0.844226 2023-12-08 21:43:25.487519 2023-12-08 21:44:40.632539   \n20      20    0.824785 2023-12-08 21:44:40.634536 2023-12-08 21:45:53.613116   \n21      21    0.910767 2023-12-08 21:45:53.614115 2023-12-08 21:47:08.808191   \n22      22    0.869827 2023-12-08 21:47:08.809190 2023-12-08 21:48:26.825224   \n23      23    0.887536 2023-12-08 21:48:26.828226 2023-12-08 21:49:43.662796   \n24      24    0.801351 2023-12-08 21:49:43.664794 2023-12-08 21:50:55.312989   \n25      25    0.864123 2023-12-08 21:50:55.313989 2023-12-08 21:52:06.601549   \n26      26    0.921453 2023-12-08 21:52:06.603549 2023-12-08 21:53:21.133330   \n27      27    0.818736 2023-12-08 21:53:21.135330 2023-12-08 21:54:38.920671   \n28      28    0.805996 2023-12-08 21:54:38.922671 2023-12-08 21:55:53.215052   \n29      29    0.727278 2023-12-08 21:55:53.217051 2023-12-08 21:57:02.905770   \n30      30    0.877831 2023-12-08 21:57:02.907769 2023-12-08 21:58:09.876385   \n31      31    0.867115 2023-12-08 21:58:09.877386 2023-12-08 21:59:21.568161   \n32      32    0.873196 2023-12-08 21:59:21.569159 2023-12-08 22:00:38.177025   \n33      33    0.855848 2023-12-08 22:00:38.179024 2023-12-08 22:01:56.233926   \n34      34   -0.402203 2023-12-08 22:01:56.234927 2023-12-08 22:03:07.607395   \n35      35    0.863671 2023-12-08 22:03:07.608395 2023-12-08 22:04:20.411379   \n36      36    0.866602 2023-12-08 22:04:20.413379 2023-12-08 22:05:38.502934   \n37      37    0.810529 2023-12-08 22:05:38.503934 2023-12-08 22:07:00.850976   \n38      38    0.839970 2023-12-08 22:07:00.853364 2023-12-08 22:08:15.189347   \n39      39    0.714966 2023-12-08 22:08:15.190347 2023-12-08 22:09:27.022193   \n40      40    0.794804 2023-12-08 22:09:27.023191 2023-12-08 22:10:44.378363   \n41      41    0.825988 2023-12-08 22:10:44.379363 2023-12-08 22:12:04.288934   \n42      42    0.903723 2023-12-08 22:12:04.290935 2023-12-08 22:13:15.338374   \n43      43    0.891442 2023-12-08 22:13:15.339372 2023-12-08 22:14:31.522418   \n44      44    0.892876 2023-12-08 22:14:31.524415 2023-12-08 22:15:45.127188   \n45      45   -0.002770 2023-12-08 22:15:45.128180 2023-12-08 22:17:02.027211   \n46      46    0.812987 2023-12-08 22:17:02.029121 2023-12-08 22:18:21.891415   \n47      47    0.850032 2023-12-08 22:18:21.893414 2023-12-08 22:19:49.092493   \n48      48    0.949696 2023-12-08 22:19:49.094493 2023-12-08 22:21:17.553884   \n49      49    0.866890 2023-12-08 22:21:17.555883 2023-12-08 22:22:45.587497   \n\n                 duration  params_batcher  params_learning_rate  \\\n0  0 days 00:01:09.685457            True              0.008647   \n1  0 days 00:01:10.901479           False              0.000698   \n2  0 days 00:01:15.776492           False              0.004319   \n3  0 days 00:01:15.909215           False              0.006581   \n4  0 days 00:01:12.403907           False              0.000179   \n5  0 days 00:01:08.827243            True              0.000043   \n6  0 days 00:01:12.722845           False              0.000023   \n7  0 days 00:01:13.074016            True              0.000072   \n8  0 days 00:01:17.437485            True              0.000011   \n9  0 days 00:01:16.036804           False              0.000200   \n10 0 days 00:01:08.396838           False              0.001378   \n11 0 days 00:01:13.975994            True              0.009356   \n12 0 days 00:01:12.021017            True              0.009598   \n13 0 days 00:01:16.156771            True              0.002550   \n14 0 days 00:01:12.869376            True              0.002825   \n15 0 days 00:01:08.692008           False              0.000892   \n16 0 days 00:01:13.016161           False              0.009499   \n17 0 days 00:01:18.192918            True              0.004230   \n18 0 days 00:01:20.578780            True              0.000454   \n19 0 days 00:01:15.145020           False              0.001915   \n20 0 days 00:01:12.978580           False              0.004303   \n21 0 days 00:01:15.194076            True              0.008959   \n22 0 days 00:01:18.016034            True              0.006455   \n23 0 days 00:01:16.834570            True              0.004485   \n24 0 days 00:01:11.648195            True              0.001534   \n25 0 days 00:01:11.287560            True              0.003373   \n26 0 days 00:01:14.529781            True              0.005501   \n27 0 days 00:01:17.785341            True              0.009711   \n28 0 days 00:01:14.292381            True              0.002232   \n29 0 days 00:01:09.688719            True              0.006367   \n30 0 days 00:01:06.968616            True              0.006129   \n31 0 days 00:01:11.690775            True              0.004193   \n32 0 days 00:01:16.607866            True              0.005882   \n33 0 days 00:01:18.054902            True              0.002780   \n34 0 days 00:01:11.372468            True              0.009355   \n35 0 days 00:01:12.802984            True              0.004312   \n36 0 days 00:01:18.089555            True              0.006279   \n37 0 days 00:01:22.347042            True              0.001127   \n38 0 days 00:01:14.335983            True              0.001824   \n39 0 days 00:01:11.831846            True              0.003210   \n40 0 days 00:01:17.355172            True              0.000735   \n41 0 days 00:01:19.909571           False              0.006702   \n42 0 days 00:01:11.047439           False              0.005310   \n43 0 days 00:01:16.183046           False              0.004431   \n44 0 days 00:01:13.602773           False              0.007328   \n45 0 days 00:01:16.899031           False              0.009969   \n46 0 days 00:01:19.862294           False              0.007524   \n47 0 days 00:01:27.199079           False              0.002017   \n48 0 days 00:01:28.459391           False              0.007699   \n49 0 days 00:01:28.031614           False              0.003122   \n\n    params_n_dim_0  params_n_dim_1  params_n_dim_2  params_n_dim_3  \\\n0            181.0           132.0           125.0             NaN   \n1            190.0             NaN             NaN             NaN   \n2            403.0           324.0           495.0             NaN   \n3            274.0            11.0           427.0             NaN   \n4            441.0             NaN             NaN             NaN   \n5              NaN             NaN             NaN             NaN   \n6            219.0           420.0           163.0           378.0   \n7              NaN             NaN             NaN             NaN   \n8            494.0            42.0             NaN             NaN   \n9            257.0           185.0           423.0           352.0   \n10            15.0             1.0           331.0             NaN   \n11           111.0           145.0            33.0             NaN   \n12           330.0           134.0             NaN             NaN   \n13           334.0            85.0             NaN             NaN   \n14           308.0             NaN             NaN             NaN   \n15           361.0           255.0             NaN             NaN   \n16           298.0           227.0           314.0             5.0   \n17           118.0            85.0           510.0             NaN   \n18           377.0            10.0             NaN             NaN   \n19           271.0             NaN             NaN             NaN   \n20           457.0           319.0           365.0             NaN   \n21           175.0           142.0             NaN             NaN   \n22           154.0           122.0             NaN             NaN   \n23           216.0           193.0             NaN             NaN   \n24            76.0             NaN             NaN             NaN   \n25           224.0           192.0             NaN             NaN   \n26           228.0           299.0             NaN             NaN   \n27           150.0           309.0             NaN             NaN   \n28            66.0             NaN             NaN             NaN   \n29           325.0           437.0             NaN             NaN   \n30           238.0             NaN             NaN             NaN   \n31           202.0           214.0             NaN             NaN   \n32           159.0           279.0             NaN             NaN   \n33           187.0           362.0             NaN             NaN   \n34           252.0           512.0           211.0             NaN   \n35           184.0             NaN             NaN             NaN   \n36           280.0           153.0             8.0             NaN   \n37           354.0            87.0             NaN             NaN   \n38           399.0             NaN             NaN             NaN   \n39             NaN             NaN             NaN             NaN   \n40           118.0           174.0             NaN             NaN   \n41           213.0           233.0           397.0             NaN   \n42           278.0            50.0           270.0             NaN   \n43           294.0           117.0           258.0             NaN   \n44           302.0           116.0           263.0            90.0   \n45           326.0            67.0           257.0            81.0   \n46           256.0            47.0           106.0           181.0   \n47           416.0           107.0           199.0           174.0   \n48           344.0            50.0           294.0             NaN   \n49           381.0            40.0           309.0             NaN   \n\n    params_n_layers     state  \n0                 4  COMPLETE  \n1                 2  COMPLETE  \n2                 4  COMPLETE  \n3                 4  COMPLETE  \n4                 2  COMPLETE  \n5                 1  COMPLETE  \n6                 5  COMPLETE  \n7                 1  COMPLETE  \n8                 3  COMPLETE  \n9                 5  COMPLETE  \n10                4  COMPLETE  \n11                4  COMPLETE  \n12                3  COMPLETE  \n13                3  COMPLETE  \n14                2  COMPLETE  \n15                3  COMPLETE  \n16                5  COMPLETE  \n17                4  COMPLETE  \n18                3  COMPLETE  \n19                2  COMPLETE  \n20                4  COMPLETE  \n21                3  COMPLETE  \n22                3  COMPLETE  \n23                3  COMPLETE  \n24                2  COMPLETE  \n25                3  COMPLETE  \n26                3  COMPLETE  \n27                3  COMPLETE  \n28                2  COMPLETE  \n29                3  COMPLETE  \n30                2  COMPLETE  \n31                3  COMPLETE  \n32                3  COMPLETE  \n33                3  COMPLETE  \n34                4  COMPLETE  \n35                2  COMPLETE  \n36                4  COMPLETE  \n37                3  COMPLETE  \n38                2  COMPLETE  \n39                1  COMPLETE  \n40                3  COMPLETE  \n41                4  COMPLETE  \n42                4  COMPLETE  \n43                4  COMPLETE  \n44                5  COMPLETE  \n45                5  COMPLETE  \n46                5  COMPLETE  \n47                5  COMPLETE  \n48                4  COMPLETE  \n49                4  COMPLETE  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_batcher</th>\n      <th>params_learning_rate</th>\n      <th>params_n_dim_0</th>\n      <th>params_n_dim_1</th>\n      <th>params_n_dim_2</th>\n      <th>params_n_dim_3</th>\n      <th>params_n_layers</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.866006</td>\n      <td>2023-12-08 21:20:08.788536</td>\n      <td>2023-12-08 21:21:18.473993</td>\n      <td>0 days 00:01:09.685457</td>\n      <td>True</td>\n      <td>0.008647</td>\n      <td>181.0</td>\n      <td>132.0</td>\n      <td>125.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.797204</td>\n      <td>2023-12-08 21:21:18.474991</td>\n      <td>2023-12-08 21:22:29.376470</td>\n      <td>0 days 00:01:10.901479</td>\n      <td>False</td>\n      <td>0.000698</td>\n      <td>190.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.813047</td>\n      <td>2023-12-08 21:22:29.377470</td>\n      <td>2023-12-08 21:23:45.153962</td>\n      <td>0 days 00:01:15.776492</td>\n      <td>False</td>\n      <td>0.004319</td>\n      <td>403.0</td>\n      <td>324.0</td>\n      <td>495.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.887530</td>\n      <td>2023-12-08 21:23:45.154963</td>\n      <td>2023-12-08 21:25:01.064178</td>\n      <td>0 days 00:01:15.909215</td>\n      <td>False</td>\n      <td>0.006581</td>\n      <td>274.0</td>\n      <td>11.0</td>\n      <td>427.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.765364</td>\n      <td>2023-12-08 21:25:01.065169</td>\n      <td>2023-12-08 21:26:13.469076</td>\n      <td>0 days 00:01:12.403907</td>\n      <td>False</td>\n      <td>0.000179</td>\n      <td>441.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>-749.315467</td>\n      <td>2023-12-08 21:26:13.471076</td>\n      <td>2023-12-08 21:27:22.298319</td>\n      <td>0 days 00:01:08.827243</td>\n      <td>True</td>\n      <td>0.000043</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>-245.449412</td>\n      <td>2023-12-08 21:27:22.299318</td>\n      <td>2023-12-08 21:28:35.022163</td>\n      <td>0 days 00:01:12.722845</td>\n      <td>False</td>\n      <td>0.000023</td>\n      <td>219.0</td>\n      <td>420.0</td>\n      <td>163.0</td>\n      <td>378.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>-643.681754</td>\n      <td>2023-12-08 21:28:35.024373</td>\n      <td>2023-12-08 21:29:48.098389</td>\n      <td>0 days 00:01:13.074016</td>\n      <td>True</td>\n      <td>0.000072</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>-740.846402</td>\n      <td>2023-12-08 21:29:48.099388</td>\n      <td>2023-12-08 21:31:05.536873</td>\n      <td>0 days 00:01:17.437485</td>\n      <td>True</td>\n      <td>0.000011</td>\n      <td>494.0</td>\n      <td>42.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.749897</td>\n      <td>2023-12-08 21:31:05.537872</td>\n      <td>2023-12-08 21:32:21.574676</td>\n      <td>0 days 00:01:16.036804</td>\n      <td>False</td>\n      <td>0.000200</td>\n      <td>257.0</td>\n      <td>185.0</td>\n      <td>423.0</td>\n      <td>352.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>-13.468859</td>\n      <td>2023-12-08 21:32:21.575638</td>\n      <td>2023-12-08 21:33:29.972476</td>\n      <td>0 days 00:01:08.396838</td>\n      <td>False</td>\n      <td>0.001378</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>331.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.837639</td>\n      <td>2023-12-08 21:33:29.974478</td>\n      <td>2023-12-08 21:34:43.950472</td>\n      <td>0 days 00:01:13.975994</td>\n      <td>True</td>\n      <td>0.009356</td>\n      <td>111.0</td>\n      <td>145.0</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.931667</td>\n      <td>2023-12-08 21:34:43.951475</td>\n      <td>2023-12-08 21:35:55.972492</td>\n      <td>0 days 00:01:12.021017</td>\n      <td>True</td>\n      <td>0.009598</td>\n      <td>330.0</td>\n      <td>134.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0.851266</td>\n      <td>2023-12-08 21:35:55.973489</td>\n      <td>2023-12-08 21:37:12.130260</td>\n      <td>0 days 00:01:16.156771</td>\n      <td>True</td>\n      <td>0.002550</td>\n      <td>334.0</td>\n      <td>85.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.854453</td>\n      <td>2023-12-08 21:37:12.132261</td>\n      <td>2023-12-08 21:38:25.001637</td>\n      <td>0 days 00:01:12.869376</td>\n      <td>True</td>\n      <td>0.002825</td>\n      <td>308.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.821525</td>\n      <td>2023-12-08 21:38:25.002635</td>\n      <td>2023-12-08 21:39:33.694643</td>\n      <td>0 days 00:01:08.692008</td>\n      <td>False</td>\n      <td>0.000892</td>\n      <td>361.0</td>\n      <td>255.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>-0.029530</td>\n      <td>2023-12-08 21:39:33.696640</td>\n      <td>2023-12-08 21:40:46.712801</td>\n      <td>0 days 00:01:13.016161</td>\n      <td>False</td>\n      <td>0.009499</td>\n      <td>298.0</td>\n      <td>227.0</td>\n      <td>314.0</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.846315</td>\n      <td>2023-12-08 21:40:46.713801</td>\n      <td>2023-12-08 21:42:04.906719</td>\n      <td>0 days 00:01:18.192918</td>\n      <td>True</td>\n      <td>0.004230</td>\n      <td>118.0</td>\n      <td>85.0</td>\n      <td>510.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0.798681</td>\n      <td>2023-12-08 21:42:04.907719</td>\n      <td>2023-12-08 21:43:25.486499</td>\n      <td>0 days 00:01:20.578780</td>\n      <td>True</td>\n      <td>0.000454</td>\n      <td>377.0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>0.844226</td>\n      <td>2023-12-08 21:43:25.487519</td>\n      <td>2023-12-08 21:44:40.632539</td>\n      <td>0 days 00:01:15.145020</td>\n      <td>False</td>\n      <td>0.001915</td>\n      <td>271.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>0.824785</td>\n      <td>2023-12-08 21:44:40.634536</td>\n      <td>2023-12-08 21:45:53.613116</td>\n      <td>0 days 00:01:12.978580</td>\n      <td>False</td>\n      <td>0.004303</td>\n      <td>457.0</td>\n      <td>319.0</td>\n      <td>365.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>0.910767</td>\n      <td>2023-12-08 21:45:53.614115</td>\n      <td>2023-12-08 21:47:08.808191</td>\n      <td>0 days 00:01:15.194076</td>\n      <td>True</td>\n      <td>0.008959</td>\n      <td>175.0</td>\n      <td>142.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>0.869827</td>\n      <td>2023-12-08 21:47:08.809190</td>\n      <td>2023-12-08 21:48:26.825224</td>\n      <td>0 days 00:01:18.016034</td>\n      <td>True</td>\n      <td>0.006455</td>\n      <td>154.0</td>\n      <td>122.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>0.887536</td>\n      <td>2023-12-08 21:48:26.828226</td>\n      <td>2023-12-08 21:49:43.662796</td>\n      <td>0 days 00:01:16.834570</td>\n      <td>True</td>\n      <td>0.004485</td>\n      <td>216.0</td>\n      <td>193.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0.801351</td>\n      <td>2023-12-08 21:49:43.664794</td>\n      <td>2023-12-08 21:50:55.312989</td>\n      <td>0 days 00:01:11.648195</td>\n      <td>True</td>\n      <td>0.001534</td>\n      <td>76.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>0.864123</td>\n      <td>2023-12-08 21:50:55.313989</td>\n      <td>2023-12-08 21:52:06.601549</td>\n      <td>0 days 00:01:11.287560</td>\n      <td>True</td>\n      <td>0.003373</td>\n      <td>224.0</td>\n      <td>192.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>0.921453</td>\n      <td>2023-12-08 21:52:06.603549</td>\n      <td>2023-12-08 21:53:21.133330</td>\n      <td>0 days 00:01:14.529781</td>\n      <td>True</td>\n      <td>0.005501</td>\n      <td>228.0</td>\n      <td>299.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>0.818736</td>\n      <td>2023-12-08 21:53:21.135330</td>\n      <td>2023-12-08 21:54:38.920671</td>\n      <td>0 days 00:01:17.785341</td>\n      <td>True</td>\n      <td>0.009711</td>\n      <td>150.0</td>\n      <td>309.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>0.805996</td>\n      <td>2023-12-08 21:54:38.922671</td>\n      <td>2023-12-08 21:55:53.215052</td>\n      <td>0 days 00:01:14.292381</td>\n      <td>True</td>\n      <td>0.002232</td>\n      <td>66.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>0.727278</td>\n      <td>2023-12-08 21:55:53.217051</td>\n      <td>2023-12-08 21:57:02.905770</td>\n      <td>0 days 00:01:09.688719</td>\n      <td>True</td>\n      <td>0.006367</td>\n      <td>325.0</td>\n      <td>437.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>0.877831</td>\n      <td>2023-12-08 21:57:02.907769</td>\n      <td>2023-12-08 21:58:09.876385</td>\n      <td>0 days 00:01:06.968616</td>\n      <td>True</td>\n      <td>0.006129</td>\n      <td>238.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>0.867115</td>\n      <td>2023-12-08 21:58:09.877386</td>\n      <td>2023-12-08 21:59:21.568161</td>\n      <td>0 days 00:01:11.690775</td>\n      <td>True</td>\n      <td>0.004193</td>\n      <td>202.0</td>\n      <td>214.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>0.873196</td>\n      <td>2023-12-08 21:59:21.569159</td>\n      <td>2023-12-08 22:00:38.177025</td>\n      <td>0 days 00:01:16.607866</td>\n      <td>True</td>\n      <td>0.005882</td>\n      <td>159.0</td>\n      <td>279.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>0.855848</td>\n      <td>2023-12-08 22:00:38.179024</td>\n      <td>2023-12-08 22:01:56.233926</td>\n      <td>0 days 00:01:18.054902</td>\n      <td>True</td>\n      <td>0.002780</td>\n      <td>187.0</td>\n      <td>362.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>-0.402203</td>\n      <td>2023-12-08 22:01:56.234927</td>\n      <td>2023-12-08 22:03:07.607395</td>\n      <td>0 days 00:01:11.372468</td>\n      <td>True</td>\n      <td>0.009355</td>\n      <td>252.0</td>\n      <td>512.0</td>\n      <td>211.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>0.863671</td>\n      <td>2023-12-08 22:03:07.608395</td>\n      <td>2023-12-08 22:04:20.411379</td>\n      <td>0 days 00:01:12.802984</td>\n      <td>True</td>\n      <td>0.004312</td>\n      <td>184.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>0.866602</td>\n      <td>2023-12-08 22:04:20.413379</td>\n      <td>2023-12-08 22:05:38.502934</td>\n      <td>0 days 00:01:18.089555</td>\n      <td>True</td>\n      <td>0.006279</td>\n      <td>280.0</td>\n      <td>153.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>0.810529</td>\n      <td>2023-12-08 22:05:38.503934</td>\n      <td>2023-12-08 22:07:00.850976</td>\n      <td>0 days 00:01:22.347042</td>\n      <td>True</td>\n      <td>0.001127</td>\n      <td>354.0</td>\n      <td>87.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>0.839970</td>\n      <td>2023-12-08 22:07:00.853364</td>\n      <td>2023-12-08 22:08:15.189347</td>\n      <td>0 days 00:01:14.335983</td>\n      <td>True</td>\n      <td>0.001824</td>\n      <td>399.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>0.714966</td>\n      <td>2023-12-08 22:08:15.190347</td>\n      <td>2023-12-08 22:09:27.022193</td>\n      <td>0 days 00:01:11.831846</td>\n      <td>True</td>\n      <td>0.003210</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>0.794804</td>\n      <td>2023-12-08 22:09:27.023191</td>\n      <td>2023-12-08 22:10:44.378363</td>\n      <td>0 days 00:01:17.355172</td>\n      <td>True</td>\n      <td>0.000735</td>\n      <td>118.0</td>\n      <td>174.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>0.825988</td>\n      <td>2023-12-08 22:10:44.379363</td>\n      <td>2023-12-08 22:12:04.288934</td>\n      <td>0 days 00:01:19.909571</td>\n      <td>False</td>\n      <td>0.006702</td>\n      <td>213.0</td>\n      <td>233.0</td>\n      <td>397.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>0.903723</td>\n      <td>2023-12-08 22:12:04.290935</td>\n      <td>2023-12-08 22:13:15.338374</td>\n      <td>0 days 00:01:11.047439</td>\n      <td>False</td>\n      <td>0.005310</td>\n      <td>278.0</td>\n      <td>50.0</td>\n      <td>270.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>0.891442</td>\n      <td>2023-12-08 22:13:15.339372</td>\n      <td>2023-12-08 22:14:31.522418</td>\n      <td>0 days 00:01:16.183046</td>\n      <td>False</td>\n      <td>0.004431</td>\n      <td>294.0</td>\n      <td>117.0</td>\n      <td>258.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>0.892876</td>\n      <td>2023-12-08 22:14:31.524415</td>\n      <td>2023-12-08 22:15:45.127188</td>\n      <td>0 days 00:01:13.602773</td>\n      <td>False</td>\n      <td>0.007328</td>\n      <td>302.0</td>\n      <td>116.0</td>\n      <td>263.0</td>\n      <td>90.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>-0.002770</td>\n      <td>2023-12-08 22:15:45.128180</td>\n      <td>2023-12-08 22:17:02.027211</td>\n      <td>0 days 00:01:16.899031</td>\n      <td>False</td>\n      <td>0.009969</td>\n      <td>326.0</td>\n      <td>67.0</td>\n      <td>257.0</td>\n      <td>81.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>0.812987</td>\n      <td>2023-12-08 22:17:02.029121</td>\n      <td>2023-12-08 22:18:21.891415</td>\n      <td>0 days 00:01:19.862294</td>\n      <td>False</td>\n      <td>0.007524</td>\n      <td>256.0</td>\n      <td>47.0</td>\n      <td>106.0</td>\n      <td>181.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>0.850032</td>\n      <td>2023-12-08 22:18:21.893414</td>\n      <td>2023-12-08 22:19:49.092493</td>\n      <td>0 days 00:01:27.199079</td>\n      <td>False</td>\n      <td>0.002017</td>\n      <td>416.0</td>\n      <td>107.0</td>\n      <td>199.0</td>\n      <td>174.0</td>\n      <td>5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>0.949696</td>\n      <td>2023-12-08 22:19:49.094493</td>\n      <td>2023-12-08 22:21:17.553884</td>\n      <td>0 days 00:01:28.459391</td>\n      <td>False</td>\n      <td>0.007699</td>\n      <td>344.0</td>\n      <td>50.0</td>\n      <td>294.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>0.866890</td>\n      <td>2023-12-08 22:21:17.555883</td>\n      <td>2023-12-08 22:22:45.587497</td>\n      <td>0 days 00:01:28.031614</td>\n      <td>False</td>\n      <td>0.003122</td>\n      <td>381.0</td>\n      <td>40.0</td>\n      <td>309.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tree = study_tree.trials_dataframe()\n",
    "df_tree.to_csv(\"study_label-tree_baseline_normalized.csv\")\n",
    "display(df_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T22:22:45.669286Z",
     "end_time": "2023-12-08T22:22:45.683285Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting global parameters\n",
    "dataset_path = \"../../datasets/\"\n",
    "label = \"default\" # alt: tree or default\n",
    "test_perc = 0.3\n",
    "val_perc = 0.21\n",
    "stability_count = 5\n",
    "n_trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:17:34.920905Z",
     "end_time": "2023-12-08T09:33:31.877283Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 22:22:45,684] A new study created in memory with name: Best default label config\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "beecee9664fe4ca7956aacbed6e38d5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 22:24:16,389] Trial 0 finished with value: -184.2231543784893 and parameters: {'learning_rate': 0.00023625067855551036, 'batcher': True, 'n_layers': 2, 'n_dim_0': 164}. Best is trial 0 with value: -184.2231543784893.\n",
      "[I 2023-12-08 22:25:48,724] Trial 1 finished with value: -3.1922308677762836 and parameters: {'learning_rate': 0.0049030985026801656, 'batcher': False, 'n_layers': 3, 'n_dim_0': 403, 'n_dim_1': 244}. Best is trial 1 with value: -3.1922308677762836.\n",
      "[I 2023-12-08 22:27:17,114] Trial 2 finished with value: -4.982813001550577 and parameters: {'learning_rate': 0.0020021147337254282, 'batcher': True, 'n_layers': 2, 'n_dim_0': 181}. Best is trial 1 with value: -3.1922308677762836.\n",
      "[I 2023-12-08 22:28:41,967] Trial 3 finished with value: -4452.742046561163 and parameters: {'learning_rate': 1.2647006209202626e-05, 'batcher': True, 'n_layers': 2, 'n_dim_0': 406}. Best is trial 1 with value: -3.1922308677762836.\n",
      "[I 2023-12-08 22:30:09,871] Trial 4 finished with value: -4525.041216810159 and parameters: {'learning_rate': 7.159865181089833e-05, 'batcher': False, 'n_layers': 1}. Best is trial 1 with value: -3.1922308677762836.\n",
      "[I 2023-12-08 22:31:41,860] Trial 5 finished with value: -5.031776397197523 and parameters: {'learning_rate': 0.000454917472706396, 'batcher': True, 'n_layers': 5, 'n_dim_0': 392, 'n_dim_1': 59, 'n_dim_2': 448, 'n_dim_3': 132}. Best is trial 1 with value: -3.1922308677762836.\n"
     ]
    }
   ],
   "source": [
    "study_default = optuna.create_study(study_name=\"Best default label config\", directions=['maximize'])\n",
    "study_default.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T10:07:14.106331Z",
     "end_time": "2023-12-08T10:07:14.135887Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_par_default = study_default.best_params\n",
    "print(best_par_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T10:07:14.588971Z",
     "end_time": "2023-12-08T10:07:14.627024Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "study_default.sampler.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T10:07:15.054042Z",
     "end_time": "2023-12-08T10:07:15.116807Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_default = study_default.trials_dataframe()\n",
    "df_default.to_csv(\"study_label-default_baseline_normalized.csv\")\n",
    "display(df_default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
